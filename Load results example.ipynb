{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_DIR = \"./adult/concatenate/checkpoint\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainable(config, checkpoint_dir=CHECKPOINT_DIR):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-24 11:52:11,915\tINFO trial_runner.py:488 -- A local experiment checkpoint was found and will be used to restore the previous experiment state.\n",
      "2022-02-24 11:52:11,928\tWARNING trial_runner.py:601 -- Attempting to resume experiment from /home/uriel/Documentos/CIC/DCC/Papers/Tabular Transformer/transformer-tabular-data/adult/concatenate/checkpoint/param_search. This will ignore any new changes to the specification.\n",
      "2022-02-24 11:52:11,981\tINFO tune.py:551 -- TrialRunner resumed, ignoring new add_experiment but updating trial resources.\n",
      "2022-02-24 11:52:11,982\tWARNING tune.py:580 -- Tune detects GPUs, but no trials are using GPUs. To enable trials to use GPUs, set tune.run(resources_per_trial={'gpu': 1}...) which allows Tune to expose 1 GPU to each trial. You can also override `Trainable.default_resource_request` if using the Trainable API.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-24 11:52:12 (running for 00:00:00.20)<br>Memory usage on this node: 12.7/15.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/12 CPUs, 0/1 GPUs, 0.0/2.69 GiB heap, 0.0/1.34 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/uriel/Documentos/CIC/DCC/Papers/Tabular Transformer/transformer-tabular-data/adult/concatenate/checkpoint/param_search<br>Number of trials: 30 (30 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name        </th><th>status    </th><th>loc               </th><th style=\"text-align: right;\">  dropout</th><th style=\"text-align: right;\">  embedding_size</th><th style=\"text-align: right;\">  n_head</th><th style=\"text-align: right;\">  n_hid</th><th style=\"text-align: right;\">  n_layers</th><th style=\"text-align: right;\">  optimizer__lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  train_loss</th><th style=\"text-align: right;\">  valid_loss</th><th style=\"text-align: right;\">  balanced_accuracy</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>trainable_01671fb6</td><td>TERMINATED</td><td>192.168.1.72:13910</td><td style=\"text-align: right;\">0.233039 </td><td style=\"text-align: right;\">            1024</td><td style=\"text-align: right;\">       4</td><td style=\"text-align: right;\">     32</td><td style=\"text-align: right;\">         2</td><td style=\"text-align: right;\">    0.0116585  </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">        148.259 </td><td style=\"text-align: right;\">    0.38132 </td><td style=\"text-align: right;\">    0.511177</td><td style=\"text-align: right;\">           0.801337</td></tr>\n",
       "<tr><td>trainable_02369e76</td><td>TERMINATED</td><td>192.168.1.72:10580</td><td style=\"text-align: right;\">0.314713 </td><td style=\"text-align: right;\">              32</td><td style=\"text-align: right;\">      32</td><td style=\"text-align: right;\">     32</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">    0.000339303</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         50.5565</td><td style=\"text-align: right;\">    0.414604</td><td style=\"text-align: right;\">    0.399503</td><td style=\"text-align: right;\">           0.610567</td></tr>\n",
       "<tr><td>trainable_096db176</td><td>TERMINATED</td><td>192.168.1.72:13440</td><td style=\"text-align: right;\">0.426513 </td><td style=\"text-align: right;\">             256</td><td style=\"text-align: right;\">       2</td><td style=\"text-align: right;\">     32</td><td style=\"text-align: right;\">         2</td><td style=\"text-align: right;\">    0.00245098 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         66.5867</td><td style=\"text-align: right;\">    0.330682</td><td style=\"text-align: right;\">    0.373728</td><td style=\"text-align: right;\">           0.813552</td></tr>\n",
       "<tr><td>trainable_0ae8a390</td><td>TERMINATED</td><td>192.168.1.72:12543</td><td style=\"text-align: right;\">0.233162 </td><td style=\"text-align: right;\">              32</td><td style=\"text-align: right;\">       4</td><td style=\"text-align: right;\">     32</td><td style=\"text-align: right;\">         2</td><td style=\"text-align: right;\">    0.00225311 </td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">        412.697 </td><td style=\"text-align: right;\">    0.325554</td><td style=\"text-align: right;\">    0.328214</td><td style=\"text-align: right;\">           0.779651</td></tr>\n",
       "<tr><td>trainable_22fed74a</td><td>TERMINATED</td><td>192.168.1.72:10644</td><td style=\"text-align: right;\">0.0802707</td><td style=\"text-align: right;\">              32</td><td style=\"text-align: right;\">      32</td><td style=\"text-align: right;\">     32</td><td style=\"text-align: right;\">         2</td><td style=\"text-align: right;\">    0.000373704</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         61.0705</td><td style=\"text-align: right;\">    0.389512</td><td style=\"text-align: right;\">    0.383938</td><td style=\"text-align: right;\">           0.691747</td></tr>\n",
       "<tr><td>trainable_24384d88</td><td>TERMINATED</td><td>192.168.1.72:11712</td><td style=\"text-align: right;\">0.150448 </td><td style=\"text-align: right;\">              32</td><td style=\"text-align: right;\">      32</td><td style=\"text-align: right;\">    256</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">    0.000955098</td><td style=\"text-align: right;\">    60</td><td style=\"text-align: right;\">        203.72  </td><td style=\"text-align: right;\">    0.335249</td><td style=\"text-align: right;\">    0.3347  </td><td style=\"text-align: right;\">           0.753022</td></tr>\n",
       "<tr><td>trainable_2b1fc86c</td><td>TERMINATED</td><td>192.168.1.72:14076</td><td style=\"text-align: right;\">0.241161 </td><td style=\"text-align: right;\">            1024</td><td style=\"text-align: right;\">       4</td><td style=\"text-align: right;\">     32</td><td style=\"text-align: right;\">         3</td><td style=\"text-align: right;\">    0.00915828 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">        207.306 </td><td style=\"text-align: right;\">    0.369911</td><td style=\"text-align: right;\">    0.553414</td><td style=\"text-align: right;\">           0.809409</td></tr>\n",
       "<tr><td>trainable_321a27b6</td><td>TERMINATED</td><td>192.168.1.72:5879 </td><td style=\"text-align: right;\">0.357689 </td><td style=\"text-align: right;\">              64</td><td style=\"text-align: right;\">       2</td><td style=\"text-align: right;\">    512</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">    0.000269289</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.6918</td><td style=\"text-align: right;\">    0.389036</td><td style=\"text-align: right;\">    0.37789 </td><td style=\"text-align: right;\">           0.678764</td></tr>\n",
       "<tr><td>trainable_432f5b20</td><td>TERMINATED</td><td>192.168.1.72:10707</td><td style=\"text-align: right;\">0.100098 </td><td style=\"text-align: right;\">              32</td><td style=\"text-align: right;\">       2</td><td style=\"text-align: right;\">     32</td><td style=\"text-align: right;\">         2</td><td style=\"text-align: right;\">    0.00317646 </td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">        412.544 </td><td style=\"text-align: right;\">    0.322022</td><td style=\"text-align: right;\">    0.330959</td><td style=\"text-align: right;\">           0.789062</td></tr>\n",
       "<tr><td>trainable_4cc02af0</td><td>TERMINATED</td><td>192.168.1.72:11787</td><td style=\"text-align: right;\">0.151776 </td><td style=\"text-align: right;\">              32</td><td style=\"text-align: right;\">      32</td><td style=\"text-align: right;\">    256</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">    0.000732652</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         51.7489</td><td style=\"text-align: right;\">    0.37114 </td><td style=\"text-align: right;\">    0.364981</td><td style=\"text-align: right;\">           0.716121</td></tr>\n",
       "<tr><td>trainable_5b4e98b6</td><td>TERMINATED</td><td>192.168.1.72:5872 </td><td style=\"text-align: right;\">0.168447 </td><td style=\"text-align: right;\">             128</td><td style=\"text-align: right;\">       8</td><td style=\"text-align: right;\">   1024</td><td style=\"text-align: right;\">         2</td><td style=\"text-align: right;\">    0.0130373  </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         66.5125</td><td style=\"text-align: right;\">    0.332985</td><td style=\"text-align: right;\">    0.439841</td><td style=\"text-align: right;\">           0.822707</td></tr>\n",
       "<tr><td>trainable_5ecb73e2</td><td>TERMINATED</td><td>192.168.1.72:5882 </td><td style=\"text-align: right;\">0.283534 </td><td style=\"text-align: right;\">              32</td><td style=\"text-align: right;\">      32</td><td style=\"text-align: right;\">    256</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">    0.000933999</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">        350.885 </td><td style=\"text-align: right;\">    0.332711</td><td style=\"text-align: right;\">    0.331978</td><td style=\"text-align: right;\">           0.756741</td></tr>\n",
       "<tr><td>trainable_5fa454e6</td><td>TERMINATED</td><td>192.168.1.72:5881 </td><td style=\"text-align: right;\">0.361356 </td><td style=\"text-align: right;\">             256</td><td style=\"text-align: right;\">      32</td><td style=\"text-align: right;\">     64</td><td style=\"text-align: right;\">         3</td><td style=\"text-align: right;\">    0.000157965</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         85.3862</td><td style=\"text-align: right;\">    0.382354</td><td style=\"text-align: right;\">    0.368111</td><td style=\"text-align: right;\">           0.754909</td></tr>\n",
       "<tr><td>trainable_61e56ea0</td><td>TERMINATED</td><td>192.168.1.72:11246</td><td style=\"text-align: right;\">0.0919553</td><td style=\"text-align: right;\">             512</td><td style=\"text-align: right;\">       2</td><td style=\"text-align: right;\">     32</td><td style=\"text-align: right;\">         3</td><td style=\"text-align: right;\">    0.00454325 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         98.4424</td><td style=\"text-align: right;\">    0.336011</td><td style=\"text-align: right;\">    0.442311</td><td style=\"text-align: right;\">           0.823767</td></tr>\n",
       "<tr><td>trainable_672a49fe</td><td>TERMINATED</td><td>192.168.1.72:5873 </td><td style=\"text-align: right;\">0.287286 </td><td style=\"text-align: right;\">             256</td><td style=\"text-align: right;\">      16</td><td style=\"text-align: right;\">    256</td><td style=\"text-align: right;\">         3</td><td style=\"text-align: right;\">    2.67006e-05</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         83.7619</td><td style=\"text-align: right;\">    0.466521</td><td style=\"text-align: right;\">    0.442448</td><td style=\"text-align: right;\">           0.5067  </td></tr>\n",
       "<tr><td>trainable_69ee27b4</td><td>TERMINATED</td><td>192.168.1.72:10806</td><td style=\"text-align: right;\">0.233562 </td><td style=\"text-align: right;\">             128</td><td style=\"text-align: right;\">       2</td><td style=\"text-align: right;\">   1024</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">    0.00371701 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         52.7339</td><td style=\"text-align: right;\">    0.327929</td><td style=\"text-align: right;\">    0.36675 </td><td style=\"text-align: right;\">           0.813207</td></tr>\n",
       "<tr><td>trainable_7cf98922</td><td>TERMINATED</td><td>192.168.1.72:5875 </td><td style=\"text-align: right;\">0.210288 </td><td style=\"text-align: right;\">            1024</td><td style=\"text-align: right;\">       8</td><td style=\"text-align: right;\">     64</td><td style=\"text-align: right;\">         2</td><td style=\"text-align: right;\">    1.59845e-05</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">        150.971 </td><td style=\"text-align: right;\">    0.395448</td><td style=\"text-align: right;\">    0.38155 </td><td style=\"text-align: right;\">           0.695639</td></tr>\n",
       "<tr><td>trainable_8346556e</td><td>TERMINATED</td><td>192.168.1.72:11395</td><td style=\"text-align: right;\">0.0873231</td><td style=\"text-align: right;\">             512</td><td style=\"text-align: right;\">       2</td><td style=\"text-align: right;\">     32</td><td style=\"text-align: right;\">         3</td><td style=\"text-align: right;\">    0.00496228 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         98.8314</td><td style=\"text-align: right;\">    0.334237</td><td style=\"text-align: right;\">    0.410944</td><td style=\"text-align: right;\">           0.819171</td></tr>\n",
       "<tr><td>trainable_892694e0</td><td>TERMINATED</td><td>192.168.1.72:5874 </td><td style=\"text-align: right;\">0.498744 </td><td style=\"text-align: right;\">              64</td><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">    256</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">    0.00200387 </td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">        346.993 </td><td style=\"text-align: right;\">    0.327245</td><td style=\"text-align: right;\">    0.33497 </td><td style=\"text-align: right;\">           0.791526</td></tr>\n",
       "<tr><td>trainable_8e3e14ca</td><td>TERMINATED</td><td>192.168.1.72:5878 </td><td style=\"text-align: right;\">0.0153575</td><td style=\"text-align: right;\">              64</td><td style=\"text-align: right;\">      32</td><td style=\"text-align: right;\">     32</td><td style=\"text-align: right;\">         4</td><td style=\"text-align: right;\">    3.43542e-05</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         94.3022</td><td style=\"text-align: right;\">    0.520586</td><td style=\"text-align: right;\">    0.524892</td><td style=\"text-align: right;\">           0.5     </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 10 more trials not shown (10 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-24 11:52:12 (running for 00:00:00.21)<br>Memory usage on this node: 12.7/15.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/12 CPUs, 0/1 GPUs, 0.0/2.69 GiB heap, 0.0/1.34 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/uriel/Documentos/CIC/DCC/Papers/Tabular Transformer/transformer-tabular-data/adult/concatenate/checkpoint/param_search<br>Number of trials: 30 (30 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name        </th><th>status    </th><th>loc               </th><th style=\"text-align: right;\">    dropout</th><th style=\"text-align: right;\">  embedding_size</th><th style=\"text-align: right;\">  n_head</th><th style=\"text-align: right;\">  n_hid</th><th style=\"text-align: right;\">  n_layers</th><th style=\"text-align: right;\">  optimizer__lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  train_loss</th><th style=\"text-align: right;\">  valid_loss</th><th style=\"text-align: right;\">  balanced_accuracy</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>trainable_2b1fc86c</td><td>TERMINATED</td><td>192.168.1.72:14076</td><td style=\"text-align: right;\">0.241161   </td><td style=\"text-align: right;\">            1024</td><td style=\"text-align: right;\">       4</td><td style=\"text-align: right;\">     32</td><td style=\"text-align: right;\">         3</td><td style=\"text-align: right;\">    0.00915828 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">        207.306 </td><td style=\"text-align: right;\">    0.369911</td><td style=\"text-align: right;\">    0.553414</td><td style=\"text-align: right;\">           0.809409</td></tr>\n",
       "<tr><td>trainable_01671fb6</td><td>TERMINATED</td><td>192.168.1.72:13910</td><td style=\"text-align: right;\">0.233039   </td><td style=\"text-align: right;\">            1024</td><td style=\"text-align: right;\">       4</td><td style=\"text-align: right;\">     32</td><td style=\"text-align: right;\">         2</td><td style=\"text-align: right;\">    0.0116585  </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">        148.259 </td><td style=\"text-align: right;\">    0.38132 </td><td style=\"text-align: right;\">    0.511177</td><td style=\"text-align: right;\">           0.801337</td></tr>\n",
       "<tr><td>trainable_096db176</td><td>TERMINATED</td><td>192.168.1.72:13440</td><td style=\"text-align: right;\">0.426513   </td><td style=\"text-align: right;\">             256</td><td style=\"text-align: right;\">       2</td><td style=\"text-align: right;\">     32</td><td style=\"text-align: right;\">         2</td><td style=\"text-align: right;\">    0.00245098 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         66.5867</td><td style=\"text-align: right;\">    0.330682</td><td style=\"text-align: right;\">    0.373728</td><td style=\"text-align: right;\">           0.813552</td></tr>\n",
       "<tr><td>trainable_0ae8a390</td><td>TERMINATED</td><td>192.168.1.72:12543</td><td style=\"text-align: right;\">0.233162   </td><td style=\"text-align: right;\">              32</td><td style=\"text-align: right;\">       4</td><td style=\"text-align: right;\">     32</td><td style=\"text-align: right;\">         2</td><td style=\"text-align: right;\">    0.00225311 </td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">        412.697 </td><td style=\"text-align: right;\">    0.325554</td><td style=\"text-align: right;\">    0.328214</td><td style=\"text-align: right;\">           0.779651</td></tr>\n",
       "<tr><td>trainable_e8ec1c22</td><td>TERMINATED</td><td>192.168.1.72:12448</td><td style=\"text-align: right;\">0.410234   </td><td style=\"text-align: right;\">              32</td><td style=\"text-align: right;\">       2</td><td style=\"text-align: right;\">     32</td><td style=\"text-align: right;\">         2</td><td style=\"text-align: right;\">    0.00217594 </td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">        423.695 </td><td style=\"text-align: right;\">    0.328527</td><td style=\"text-align: right;\">    0.331198</td><td style=\"text-align: right;\">           0.785933</td></tr>\n",
       "<tr><td>trainable_c824748a</td><td>TERMINATED</td><td>192.168.1.72:12280</td><td style=\"text-align: right;\">0.395155   </td><td style=\"text-align: right;\">              32</td><td style=\"text-align: right;\">       2</td><td style=\"text-align: right;\">    256</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">    0.000751725</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         52.8432</td><td style=\"text-align: right;\">    0.377482</td><td style=\"text-align: right;\">    0.367473</td><td style=\"text-align: right;\">           0.707671</td></tr>\n",
       "<tr><td>trainable_4cc02af0</td><td>TERMINATED</td><td>192.168.1.72:11787</td><td style=\"text-align: right;\">0.151776   </td><td style=\"text-align: right;\">              32</td><td style=\"text-align: right;\">      32</td><td style=\"text-align: right;\">    256</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">    0.000732652</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         51.7489</td><td style=\"text-align: right;\">    0.37114 </td><td style=\"text-align: right;\">    0.364981</td><td style=\"text-align: right;\">           0.716121</td></tr>\n",
       "<tr><td>trainable_24384d88</td><td>TERMINATED</td><td>192.168.1.72:11712</td><td style=\"text-align: right;\">0.150448   </td><td style=\"text-align: right;\">              32</td><td style=\"text-align: right;\">      32</td><td style=\"text-align: right;\">    256</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">    0.000955098</td><td style=\"text-align: right;\">    60</td><td style=\"text-align: right;\">        203.72  </td><td style=\"text-align: right;\">    0.335249</td><td style=\"text-align: right;\">    0.3347  </td><td style=\"text-align: right;\">           0.753022</td></tr>\n",
       "<tr><td>trainable_fce0c562</td><td>TERMINATED</td><td>192.168.1.72:11644</td><td style=\"text-align: right;\">0.0238158  </td><td style=\"text-align: right;\">              32</td><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">     32</td><td style=\"text-align: right;\">         2</td><td style=\"text-align: right;\">    9.3851e-05 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         63.7961</td><td style=\"text-align: right;\">    0.467826</td><td style=\"text-align: right;\">    0.469117</td><td style=\"text-align: right;\">           0.511171</td></tr>\n",
       "<tr><td>trainable_c01435b0</td><td>TERMINATED</td><td>192.168.1.72:11501</td><td style=\"text-align: right;\">0.000104231</td><td style=\"text-align: right;\">              32</td><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">     32</td><td style=\"text-align: right;\">         2</td><td style=\"text-align: right;\">    6.88139e-05</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         62.768 </td><td style=\"text-align: right;\">    0.483364</td><td style=\"text-align: right;\">    0.485507</td><td style=\"text-align: right;\">           0.500419</td></tr>\n",
       "<tr><td>trainable_8346556e</td><td>TERMINATED</td><td>192.168.1.72:11395</td><td style=\"text-align: right;\">0.0873231  </td><td style=\"text-align: right;\">             512</td><td style=\"text-align: right;\">       2</td><td style=\"text-align: right;\">     32</td><td style=\"text-align: right;\">         3</td><td style=\"text-align: right;\">    0.00496228 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         98.8314</td><td style=\"text-align: right;\">    0.334237</td><td style=\"text-align: right;\">    0.410944</td><td style=\"text-align: right;\">           0.819171</td></tr>\n",
       "<tr><td>trainable_61e56ea0</td><td>TERMINATED</td><td>192.168.1.72:11246</td><td style=\"text-align: right;\">0.0919553  </td><td style=\"text-align: right;\">             512</td><td style=\"text-align: right;\">       2</td><td style=\"text-align: right;\">     32</td><td style=\"text-align: right;\">         3</td><td style=\"text-align: right;\">    0.00454325 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         98.4424</td><td style=\"text-align: right;\">    0.336011</td><td style=\"text-align: right;\">    0.442311</td><td style=\"text-align: right;\">           0.823767</td></tr>\n",
       "<tr><td>trainable_69ee27b4</td><td>TERMINATED</td><td>192.168.1.72:10806</td><td style=\"text-align: right;\">0.233562   </td><td style=\"text-align: right;\">             128</td><td style=\"text-align: right;\">       2</td><td style=\"text-align: right;\">   1024</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">    0.00371701 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         52.7339</td><td style=\"text-align: right;\">    0.327929</td><td style=\"text-align: right;\">    0.36675 </td><td style=\"text-align: right;\">           0.813207</td></tr>\n",
       "<tr><td>trainable_432f5b20</td><td>TERMINATED</td><td>192.168.1.72:10707</td><td style=\"text-align: right;\">0.100098   </td><td style=\"text-align: right;\">              32</td><td style=\"text-align: right;\">       2</td><td style=\"text-align: right;\">     32</td><td style=\"text-align: right;\">         2</td><td style=\"text-align: right;\">    0.00317646 </td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">        412.544 </td><td style=\"text-align: right;\">    0.322022</td><td style=\"text-align: right;\">    0.330959</td><td style=\"text-align: right;\">           0.789062</td></tr>\n",
       "<tr><td>trainable_22fed74a</td><td>TERMINATED</td><td>192.168.1.72:10644</td><td style=\"text-align: right;\">0.0802707  </td><td style=\"text-align: right;\">              32</td><td style=\"text-align: right;\">      32</td><td style=\"text-align: right;\">     32</td><td style=\"text-align: right;\">         2</td><td style=\"text-align: right;\">    0.000373704</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         61.0705</td><td style=\"text-align: right;\">    0.389512</td><td style=\"text-align: right;\">    0.383938</td><td style=\"text-align: right;\">           0.691747</td></tr>\n",
       "<tr><td>trainable_02369e76</td><td>TERMINATED</td><td>192.168.1.72:10580</td><td style=\"text-align: right;\">0.314713   </td><td style=\"text-align: right;\">              32</td><td style=\"text-align: right;\">      32</td><td style=\"text-align: right;\">     32</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">    0.000339303</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         50.5565</td><td style=\"text-align: right;\">    0.414604</td><td style=\"text-align: right;\">    0.399503</td><td style=\"text-align: right;\">           0.610567</td></tr>\n",
       "<tr><td>trainable_e16de85c</td><td>TERMINATED</td><td>192.168.1.72:10514</td><td style=\"text-align: right;\">0.280961   </td><td style=\"text-align: right;\">              32</td><td style=\"text-align: right;\">      32</td><td style=\"text-align: right;\">    128</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">    0.0696606  </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         50.9164</td><td style=\"text-align: right;\">    0.326911</td><td style=\"text-align: right;\">    0.418505</td><td style=\"text-align: right;\">           0.814836</td></tr>\n",
       "<tr><td>trainable_b7b1f1e8</td><td>TERMINATED</td><td>192.168.1.72:10420</td><td style=\"text-align: right;\">0.188085   </td><td style=\"text-align: right;\">              32</td><td style=\"text-align: right;\">      32</td><td style=\"text-align: right;\">    128</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">    0.0392573  </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         51.3973</td><td style=\"text-align: right;\">    0.328532</td><td style=\"text-align: right;\">    0.433739</td><td style=\"text-align: right;\">           0.816032</td></tr>\n",
       "<tr><td>trainable_5b4e98b6</td><td>TERMINATED</td><td>192.168.1.72:5872 </td><td style=\"text-align: right;\">0.168447   </td><td style=\"text-align: right;\">             128</td><td style=\"text-align: right;\">       8</td><td style=\"text-align: right;\">   1024</td><td style=\"text-align: right;\">         2</td><td style=\"text-align: right;\">    0.0130373  </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         66.5125</td><td style=\"text-align: right;\">    0.332985</td><td style=\"text-align: right;\">    0.439841</td><td style=\"text-align: right;\">           0.822707</td></tr>\n",
       "<tr><td>trainable_7cf98922</td><td>TERMINATED</td><td>192.168.1.72:5875 </td><td style=\"text-align: right;\">0.210288   </td><td style=\"text-align: right;\">            1024</td><td style=\"text-align: right;\">       8</td><td style=\"text-align: right;\">     64</td><td style=\"text-align: right;\">         2</td><td style=\"text-align: right;\">    1.59845e-05</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">        150.971 </td><td style=\"text-align: right;\">    0.395448</td><td style=\"text-align: right;\">    0.38155 </td><td style=\"text-align: right;\">           0.695639</td></tr>\n",
       "<tr><td>trainable_b2e4322c</td><td>TERMINATED</td><td>192.168.1.72:5880 </td><td style=\"text-align: right;\">0.477693   </td><td style=\"text-align: right;\">              32</td><td style=\"text-align: right;\">      16</td><td style=\"text-align: right;\">    512</td><td style=\"text-align: right;\">         4</td><td style=\"text-align: right;\">    0.00685602 </td><td style=\"text-align: right;\">    60</td><td style=\"text-align: right;\">        369.544 </td><td style=\"text-align: right;\">    0.32926 </td><td style=\"text-align: right;\">    0.340102</td><td style=\"text-align: right;\">           0.797648</td></tr>\n",
       "<tr><td>trainable_fa1b3f42</td><td>TERMINATED</td><td>192.168.1.72:5877 </td><td style=\"text-align: right;\">0.215179   </td><td style=\"text-align: right;\">              32</td><td style=\"text-align: right;\">      32</td><td style=\"text-align: right;\">     32</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">    0.00261564 </td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">        335.136 </td><td style=\"text-align: right;\">    0.32348 </td><td style=\"text-align: right;\">    0.3304  </td><td style=\"text-align: right;\">           0.786524</td></tr>\n",
       "<tr><td>trainable_bfb0d42a</td><td>TERMINATED</td><td>192.168.1.72:5876 </td><td style=\"text-align: right;\">0.45645    </td><td style=\"text-align: right;\">            1024</td><td style=\"text-align: right;\">       4</td><td style=\"text-align: right;\">    512</td><td style=\"text-align: right;\">         4</td><td style=\"text-align: right;\">    0.020617   </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">        306.749 </td><td style=\"text-align: right;\">    0.428095</td><td style=\"text-align: right;\">    0.566273</td><td style=\"text-align: right;\">           0.777023</td></tr>\n",
       "<tr><td>trainable_8e3e14ca</td><td>TERMINATED</td><td>192.168.1.72:5878 </td><td style=\"text-align: right;\">0.0153575  </td><td style=\"text-align: right;\">              64</td><td style=\"text-align: right;\">      32</td><td style=\"text-align: right;\">     32</td><td style=\"text-align: right;\">         4</td><td style=\"text-align: right;\">    3.43542e-05</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         94.3022</td><td style=\"text-align: right;\">    0.520586</td><td style=\"text-align: right;\">    0.524892</td><td style=\"text-align: right;\">           0.5     </td></tr>\n",
       "<tr><td>trainable_bd040662</td><td>TERMINATED</td><td>192.168.1.72:5871 </td><td style=\"text-align: right;\">0.132163   </td><td style=\"text-align: right;\">             512</td><td style=\"text-align: right;\">       4</td><td style=\"text-align: right;\">    256</td><td style=\"text-align: right;\">         2</td><td style=\"text-align: right;\">    0.00135395 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         79.3618</td><td style=\"text-align: right;\">    0.326928</td><td style=\"text-align: right;\">    0.378585</td><td style=\"text-align: right;\">           0.817507</td></tr>\n",
       "<tr><td>trainable_892694e0</td><td>TERMINATED</td><td>192.168.1.72:5874 </td><td style=\"text-align: right;\">0.498744   </td><td style=\"text-align: right;\">              64</td><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">    256</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">    0.00200387 </td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">        346.993 </td><td style=\"text-align: right;\">    0.327245</td><td style=\"text-align: right;\">    0.33497 </td><td style=\"text-align: right;\">           0.791526</td></tr>\n",
       "<tr><td>trainable_672a49fe</td><td>TERMINATED</td><td>192.168.1.72:5873 </td><td style=\"text-align: right;\">0.287286   </td><td style=\"text-align: right;\">             256</td><td style=\"text-align: right;\">      16</td><td style=\"text-align: right;\">    256</td><td style=\"text-align: right;\">         3</td><td style=\"text-align: right;\">    2.67006e-05</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         83.7619</td><td style=\"text-align: right;\">    0.466521</td><td style=\"text-align: right;\">    0.442448</td><td style=\"text-align: right;\">           0.5067  </td></tr>\n",
       "<tr><td>trainable_321a27b6</td><td>TERMINATED</td><td>192.168.1.72:5879 </td><td style=\"text-align: right;\">0.357689   </td><td style=\"text-align: right;\">              64</td><td style=\"text-align: right;\">       2</td><td style=\"text-align: right;\">    512</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">    0.000269289</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.6918</td><td style=\"text-align: right;\">    0.389036</td><td style=\"text-align: right;\">    0.37789 </td><td style=\"text-align: right;\">           0.678764</td></tr>\n",
       "<tr><td>trainable_5fa454e6</td><td>TERMINATED</td><td>192.168.1.72:5881 </td><td style=\"text-align: right;\">0.361356   </td><td style=\"text-align: right;\">             256</td><td style=\"text-align: right;\">      32</td><td style=\"text-align: right;\">     64</td><td style=\"text-align: right;\">         3</td><td style=\"text-align: right;\">    0.000157965</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         85.3862</td><td style=\"text-align: right;\">    0.382354</td><td style=\"text-align: right;\">    0.368111</td><td style=\"text-align: right;\">           0.754909</td></tr>\n",
       "<tr><td>trainable_5ecb73e2</td><td>TERMINATED</td><td>192.168.1.72:5882 </td><td style=\"text-align: right;\">0.283534   </td><td style=\"text-align: right;\">              32</td><td style=\"text-align: right;\">      32</td><td style=\"text-align: right;\">    256</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">    0.000933999</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">        350.885 </td><td style=\"text-align: right;\">    0.332711</td><td style=\"text-align: right;\">    0.331978</td><td style=\"text-align: right;\">           0.756741</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-24 11:52:12,300\tINFO tune.py:636 -- Total run time: 5.55 seconds (0.20 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "analysis = tune.run(\n",
    "    trainable,\n",
    "    resume=\"AUTO\",\n",
    "    local_dir=CHECKPOINT_DIR, \n",
    "    name=\"param_search\"    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best config:  {'n_layers': 3, 'optimizer__lr': 0.004543250039457362, 'n_head': 2, 'n_hid': 32, 'dropout': 0.09195530418741046, 'embedding_size': 512}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best config: \", analysis.get_best_config(metric=\"balanced_accuracy\", mode=\"max\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best config:  {'n_layers': 2, 'optimizer__lr': 0.002253109934551261, 'n_head': 4, 'n_hid': 32, 'dropout': 0.2331622289183567, 'embedding_size': 32}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best config: \", analysis.get_best_config(metric=\"valid_loss\", mode=\"min\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trial_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8346556e</th>\n",
       "      <td>0.410944</td>\n",
       "      <td>0.796520</td>\n",
       "      <td>0.819171</td>\n",
       "      <td>0.674738</td>\n",
       "      <td>0.863484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61e56ea0</th>\n",
       "      <td>0.442311</td>\n",
       "      <td>0.785056</td>\n",
       "      <td>0.823767</td>\n",
       "      <td>0.671670</td>\n",
       "      <td>0.899497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          valid_loss  accuracy  balanced_accuracy        f1    recall\n",
       "trial_id                                                             \n",
       "8346556e    0.410944  0.796520           0.819171  0.674738  0.863484\n",
       "61e56ea0    0.442311  0.785056           0.823767  0.671670  0.899497"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis.results_df.where(\n",
    "    (analysis.results_df[\"config.n_layers\"]==3)\n",
    "    & (analysis.results_df[\"config.n_head\"]==2)\n",
    "    & (analysis.results_df[\"config.n_hid\"]==32)\n",
    ")[[\"valid_loss\", \"accuracy\", \"balanced_accuracy\", \"f1\", \"recall\"]].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>f1</th>\n",
       "      <th>recall</th>\n",
       "      <th>time_this_iter_s</th>\n",
       "      <th>done</th>\n",
       "      <th>timesteps_total</th>\n",
       "      <th>...</th>\n",
       "      <th>node_ip</th>\n",
       "      <th>time_since_restore</th>\n",
       "      <th>timesteps_since_restore</th>\n",
       "      <th>iterations_since_restore</th>\n",
       "      <th>experiment_tag</th>\n",
       "      <th>config.n_layers</th>\n",
       "      <th>config.optimizer__lr</th>\n",
       "      <th>config.n_head</th>\n",
       "      <th>config.n_hid</th>\n",
       "      <th>config.dropout</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trial_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2b1fc86c</th>\n",
       "      <td>0.369911</td>\n",
       "      <td>0.553414</td>\n",
       "      <td>0.809409</td>\n",
       "      <td>0.753941</td>\n",
       "      <td>0.809409</td>\n",
       "      <td>0.645846</td>\n",
       "      <td>0.917923</td>\n",
       "      <td>13.669288</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>192.168.1.72</td>\n",
       "      <td>207.305803</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>30_dropout=0.24116,embedding_size=1024,n_head=...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.009158</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>0.241161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01671fb6</th>\n",
       "      <td>0.381320</td>\n",
       "      <td>0.511177</td>\n",
       "      <td>0.801337</td>\n",
       "      <td>0.786694</td>\n",
       "      <td>0.801337</td>\n",
       "      <td>0.655423</td>\n",
       "      <td>0.829983</td>\n",
       "      <td>9.870879</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>192.168.1.72</td>\n",
       "      <td>148.259154</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>29_dropout=0.23304,embedding_size=1024,n_head=...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.011659</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>0.233039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>096db176</th>\n",
       "      <td>0.330682</td>\n",
       "      <td>0.373728</td>\n",
       "      <td>0.813552</td>\n",
       "      <td>0.813715</td>\n",
       "      <td>0.813552</td>\n",
       "      <td>0.680926</td>\n",
       "      <td>0.813233</td>\n",
       "      <td>4.054139</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>192.168.1.72</td>\n",
       "      <td>66.586652</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>28_dropout=0.42651,embedding_size=256,n_head=2...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.002451</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.426513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0ae8a390</th>\n",
       "      <td>0.325554</td>\n",
       "      <td>0.328214</td>\n",
       "      <td>0.779651</td>\n",
       "      <td>0.848106</td>\n",
       "      <td>0.779651</td>\n",
       "      <td>0.675131</td>\n",
       "      <td>0.645729</td>\n",
       "      <td>4.061585</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>192.168.1.72</td>\n",
       "      <td>412.697139</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>27_dropout=0.23316,embedding_size=32,n_head=4,...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.002253</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>0.233162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e8ec1c22</th>\n",
       "      <td>0.328527</td>\n",
       "      <td>0.331198</td>\n",
       "      <td>0.785933</td>\n",
       "      <td>0.846469</td>\n",
       "      <td>0.785933</td>\n",
       "      <td>0.680034</td>\n",
       "      <td>0.667504</td>\n",
       "      <td>4.238353</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>192.168.1.72</td>\n",
       "      <td>423.694614</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>26_dropout=0.41023,embedding_size=32,n_head=2,...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.002176</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.410234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c824748a</th>\n",
       "      <td>0.377482</td>\n",
       "      <td>0.367473</td>\n",
       "      <td>0.707671</td>\n",
       "      <td>0.830092</td>\n",
       "      <td>0.707671</td>\n",
       "      <td>0.573922</td>\n",
       "      <td>0.468174</td>\n",
       "      <td>3.311373</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>192.168.1.72</td>\n",
       "      <td>52.843226</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>25_dropout=0.39516,embedding_size=32,n_head=2,...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000752</td>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>0.395155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4cc02af0</th>\n",
       "      <td>0.371140</td>\n",
       "      <td>0.364981</td>\n",
       "      <td>0.716121</td>\n",
       "      <td>0.827021</td>\n",
       "      <td>0.716121</td>\n",
       "      <td>0.585174</td>\n",
       "      <td>0.499162</td>\n",
       "      <td>3.396277</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>192.168.1.72</td>\n",
       "      <td>51.748903</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>24_dropout=0.15178,embedding_size=32,n_head=32...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000733</td>\n",
       "      <td>32</td>\n",
       "      <td>256</td>\n",
       "      <td>0.151776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24384d88</th>\n",
       "      <td>0.335249</td>\n",
       "      <td>0.334700</td>\n",
       "      <td>0.753022</td>\n",
       "      <td>0.843398</td>\n",
       "      <td>0.753022</td>\n",
       "      <td>0.642690</td>\n",
       "      <td>0.576214</td>\n",
       "      <td>3.304428</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>192.168.1.72</td>\n",
       "      <td>203.719640</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>23_dropout=0.15045,embedding_size=32,n_head=32...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000955</td>\n",
       "      <td>32</td>\n",
       "      <td>256</td>\n",
       "      <td>0.150448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fce0c562</th>\n",
       "      <td>0.467826</td>\n",
       "      <td>0.469117</td>\n",
       "      <td>0.511171</td>\n",
       "      <td>0.760901</td>\n",
       "      <td>0.511171</td>\n",
       "      <td>0.044190</td>\n",
       "      <td>0.022613</td>\n",
       "      <td>4.083665</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>192.168.1.72</td>\n",
       "      <td>63.796139</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>22_dropout=0.023816,embedding_size=32,n_head=1...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>0.023816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c01435b0</th>\n",
       "      <td>0.483364</td>\n",
       "      <td>0.485507</td>\n",
       "      <td>0.500419</td>\n",
       "      <td>0.755783</td>\n",
       "      <td>0.500419</td>\n",
       "      <td>0.001674</td>\n",
       "      <td>0.000838</td>\n",
       "      <td>4.090947</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>192.168.1.72</td>\n",
       "      <td>62.767963</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>21_dropout=0.00010423,embedding_size=32,n_head...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>0.000104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8346556e</th>\n",
       "      <td>0.334237</td>\n",
       "      <td>0.410944</td>\n",
       "      <td>0.819171</td>\n",
       "      <td>0.796520</td>\n",
       "      <td>0.819171</td>\n",
       "      <td>0.674738</td>\n",
       "      <td>0.863484</td>\n",
       "      <td>6.387970</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>192.168.1.72</td>\n",
       "      <td>98.831448</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>20_dropout=0.087323,embedding_size=512,n_head=...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.004962</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.087323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61e56ea0</th>\n",
       "      <td>0.336011</td>\n",
       "      <td>0.442311</td>\n",
       "      <td>0.823767</td>\n",
       "      <td>0.785056</td>\n",
       "      <td>0.823767</td>\n",
       "      <td>0.671670</td>\n",
       "      <td>0.899497</td>\n",
       "      <td>6.632267</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>192.168.1.72</td>\n",
       "      <td>98.442428</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>19_dropout=0.091955,embedding_size=512,n_head=...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.004543</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.091955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69ee27b4</th>\n",
       "      <td>0.327929</td>\n",
       "      <td>0.366750</td>\n",
       "      <td>0.813207</td>\n",
       "      <td>0.815763</td>\n",
       "      <td>0.813207</td>\n",
       "      <td>0.681979</td>\n",
       "      <td>0.808208</td>\n",
       "      <td>3.194201</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>192.168.1.72</td>\n",
       "      <td>52.733872</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>18_dropout=0.23356,embedding_size=128,n_head=2...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003717</td>\n",
       "      <td>2</td>\n",
       "      <td>1024</td>\n",
       "      <td>0.233562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432f5b20</th>\n",
       "      <td>0.322022</td>\n",
       "      <td>0.330959</td>\n",
       "      <td>0.789062</td>\n",
       "      <td>0.841351</td>\n",
       "      <td>0.789062</td>\n",
       "      <td>0.679089</td>\n",
       "      <td>0.686767</td>\n",
       "      <td>4.248960</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>192.168.1.72</td>\n",
       "      <td>412.544340</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>17_dropout=0.1001,embedding_size=32,n_head=2,n...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.003176</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.100098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22fed74a</th>\n",
       "      <td>0.389512</td>\n",
       "      <td>0.383938</td>\n",
       "      <td>0.691747</td>\n",
       "      <td>0.818014</td>\n",
       "      <td>0.691747</td>\n",
       "      <td>0.544336</td>\n",
       "      <td>0.444724</td>\n",
       "      <td>4.075182</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>192.168.1.72</td>\n",
       "      <td>61.070451</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>16_dropout=0.080271,embedding_size=32,n_head=3...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>0.080271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02369e76</th>\n",
       "      <td>0.414604</td>\n",
       "      <td>0.399503</td>\n",
       "      <td>0.610567</td>\n",
       "      <td>0.795087</td>\n",
       "      <td>0.610567</td>\n",
       "      <td>0.373200</td>\n",
       "      <td>0.249581</td>\n",
       "      <td>3.234192</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>192.168.1.72</td>\n",
       "      <td>50.556549</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>15_dropout=0.31471,embedding_size=32,n_head=32...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000339</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>0.314713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e16de85c</th>\n",
       "      <td>0.326911</td>\n",
       "      <td>0.418505</td>\n",
       "      <td>0.814836</td>\n",
       "      <td>0.789969</td>\n",
       "      <td>0.814836</td>\n",
       "      <td>0.667746</td>\n",
       "      <td>0.863484</td>\n",
       "      <td>3.225180</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>192.168.1.72</td>\n",
       "      <td>50.916437</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>14_dropout=0.28096,embedding_size=32,n_head=32...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.069661</td>\n",
       "      <td>32</td>\n",
       "      <td>128</td>\n",
       "      <td>0.280961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b7b1f1e8</th>\n",
       "      <td>0.328532</td>\n",
       "      <td>0.433739</td>\n",
       "      <td>0.816032</td>\n",
       "      <td>0.778506</td>\n",
       "      <td>0.816032</td>\n",
       "      <td>0.662508</td>\n",
       "      <td>0.889447</td>\n",
       "      <td>3.166104</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>192.168.1.72</td>\n",
       "      <td>51.397341</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>13_dropout=0.18809,embedding_size=32,n_head=32...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.039257</td>\n",
       "      <td>32</td>\n",
       "      <td>128</td>\n",
       "      <td>0.188085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5b4e98b6</th>\n",
       "      <td>0.332985</td>\n",
       "      <td>0.439841</td>\n",
       "      <td>0.822707</td>\n",
       "      <td>0.787308</td>\n",
       "      <td>0.822707</td>\n",
       "      <td>0.672136</td>\n",
       "      <td>0.891960</td>\n",
       "      <td>4.359169</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>192.168.1.72</td>\n",
       "      <td>66.512451</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>12_dropout=0.16845,embedding_size=128,n_head=8...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.013037</td>\n",
       "      <td>8</td>\n",
       "      <td>1024</td>\n",
       "      <td>0.168447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7cf98922</th>\n",
       "      <td>0.395448</td>\n",
       "      <td>0.381550</td>\n",
       "      <td>0.695639</td>\n",
       "      <td>0.820471</td>\n",
       "      <td>0.695639</td>\n",
       "      <td>0.551407</td>\n",
       "      <td>0.451424</td>\n",
       "      <td>9.767735</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>192.168.1.72</td>\n",
       "      <td>150.971434</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>11_dropout=0.21029,embedding_size=1024,n_head=...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>0.210288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b2e4322c</th>\n",
       "      <td>0.329260</td>\n",
       "      <td>0.340102</td>\n",
       "      <td>0.797648</td>\n",
       "      <td>0.833777</td>\n",
       "      <td>0.797648</td>\n",
       "      <td>0.681319</td>\n",
       "      <td>0.726968</td>\n",
       "      <td>5.939143</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>192.168.1.72</td>\n",
       "      <td>369.543921</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>10_dropout=0.47769,embedding_size=32,n_head=16...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.006856</td>\n",
       "      <td>16</td>\n",
       "      <td>512</td>\n",
       "      <td>0.477693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fa1b3f42</th>\n",
       "      <td>0.323480</td>\n",
       "      <td>0.330400</td>\n",
       "      <td>0.786524</td>\n",
       "      <td>0.845650</td>\n",
       "      <td>0.786524</td>\n",
       "      <td>0.679966</td>\n",
       "      <td>0.670854</td>\n",
       "      <td>3.361481</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>192.168.1.72</td>\n",
       "      <td>335.135817</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>9_dropout=0.21518,embedding_size=32,n_head=32,...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002616</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>0.215179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bfb0d42a</th>\n",
       "      <td>0.428095</td>\n",
       "      <td>0.566273</td>\n",
       "      <td>0.777023</td>\n",
       "      <td>0.780348</td>\n",
       "      <td>0.777023</td>\n",
       "      <td>0.631651</td>\n",
       "      <td>0.770519</td>\n",
       "      <td>20.496814</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>192.168.1.72</td>\n",
       "      <td>306.748746</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>8_dropout=0.45645,embedding_size=1024,n_head=4...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.020617</td>\n",
       "      <td>4</td>\n",
       "      <td>512</td>\n",
       "      <td>0.456450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8e3e14ca</th>\n",
       "      <td>0.520586</td>\n",
       "      <td>0.524892</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.755578</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.994438</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>192.168.1.72</td>\n",
       "      <td>94.302230</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>7_dropout=0.015357,embedding_size=64,n_head=32...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>0.015357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bd040662</th>\n",
       "      <td>0.326928</td>\n",
       "      <td>0.378585</td>\n",
       "      <td>0.817507</td>\n",
       "      <td>0.809417</td>\n",
       "      <td>0.817507</td>\n",
       "      <td>0.681274</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>5.433620</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>192.168.1.72</td>\n",
       "      <td>79.361793</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>6_dropout=0.13216,embedding_size=512,n_head=4,...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001354</td>\n",
       "      <td>4</td>\n",
       "      <td>256</td>\n",
       "      <td>0.132163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892694e0</th>\n",
       "      <td>0.327245</td>\n",
       "      <td>0.334970</td>\n",
       "      <td>0.791526</td>\n",
       "      <td>0.839509</td>\n",
       "      <td>0.791526</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.697655</td>\n",
       "      <td>3.454464</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>192.168.1.72</td>\n",
       "      <td>346.993001</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>5_dropout=0.49874,embedding_size=64,n_head=1,n...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002004</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>0.498744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672a49fe</th>\n",
       "      <td>0.466521</td>\n",
       "      <td>0.442448</td>\n",
       "      <td>0.506700</td>\n",
       "      <td>0.758854</td>\n",
       "      <td>0.506700</td>\n",
       "      <td>0.026446</td>\n",
       "      <td>0.013400</td>\n",
       "      <td>5.404740</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>192.168.1.72</td>\n",
       "      <td>83.761861</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>4_dropout=0.28729,embedding_size=256,n_head=16...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>16</td>\n",
       "      <td>256</td>\n",
       "      <td>0.287286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321a27b6</th>\n",
       "      <td>0.389036</td>\n",
       "      <td>0.377890</td>\n",
       "      <td>0.678764</td>\n",
       "      <td>0.821085</td>\n",
       "      <td>0.678764</td>\n",
       "      <td>0.522404</td>\n",
       "      <td>0.400335</td>\n",
       "      <td>3.379153</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>192.168.1.72</td>\n",
       "      <td>53.691812</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>3_dropout=0.35769,embedding_size=64,n_head=2,n...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>2</td>\n",
       "      <td>512</td>\n",
       "      <td>0.357689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5fa454e6</th>\n",
       "      <td>0.382354</td>\n",
       "      <td>0.368111</td>\n",
       "      <td>0.754909</td>\n",
       "      <td>0.818424</td>\n",
       "      <td>0.754909</td>\n",
       "      <td>0.629336</td>\n",
       "      <td>0.630653</td>\n",
       "      <td>5.291440</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>192.168.1.72</td>\n",
       "      <td>85.386159</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>2_dropout=0.36136,embedding_size=256,n_head=32...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>32</td>\n",
       "      <td>64</td>\n",
       "      <td>0.361356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5ecb73e2</th>\n",
       "      <td>0.332711</td>\n",
       "      <td>0.331978</td>\n",
       "      <td>0.756741</td>\n",
       "      <td>0.846878</td>\n",
       "      <td>0.756741</td>\n",
       "      <td>0.649485</td>\n",
       "      <td>0.580402</td>\n",
       "      <td>3.654984</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>192.168.1.72</td>\n",
       "      <td>350.885072</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>1_dropout=0.28353,embedding_size=32,n_head=32,...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000934</td>\n",
       "      <td>32</td>\n",
       "      <td>256</td>\n",
       "      <td>0.283534</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          train_loss  valid_loss  balanced_accuracy  accuracy   roc_auc  \\\n",
       "trial_id                                                                  \n",
       "2b1fc86c    0.369911    0.553414           0.809409  0.753941  0.809409   \n",
       "01671fb6    0.381320    0.511177           0.801337  0.786694  0.801337   \n",
       "096db176    0.330682    0.373728           0.813552  0.813715  0.813552   \n",
       "0ae8a390    0.325554    0.328214           0.779651  0.848106  0.779651   \n",
       "e8ec1c22    0.328527    0.331198           0.785933  0.846469  0.785933   \n",
       "c824748a    0.377482    0.367473           0.707671  0.830092  0.707671   \n",
       "4cc02af0    0.371140    0.364981           0.716121  0.827021  0.716121   \n",
       "24384d88    0.335249    0.334700           0.753022  0.843398  0.753022   \n",
       "fce0c562    0.467826    0.469117           0.511171  0.760901  0.511171   \n",
       "c01435b0    0.483364    0.485507           0.500419  0.755783  0.500419   \n",
       "8346556e    0.334237    0.410944           0.819171  0.796520  0.819171   \n",
       "61e56ea0    0.336011    0.442311           0.823767  0.785056  0.823767   \n",
       "69ee27b4    0.327929    0.366750           0.813207  0.815763  0.813207   \n",
       "432f5b20    0.322022    0.330959           0.789062  0.841351  0.789062   \n",
       "22fed74a    0.389512    0.383938           0.691747  0.818014  0.691747   \n",
       "02369e76    0.414604    0.399503           0.610567  0.795087  0.610567   \n",
       "e16de85c    0.326911    0.418505           0.814836  0.789969  0.814836   \n",
       "b7b1f1e8    0.328532    0.433739           0.816032  0.778506  0.816032   \n",
       "5b4e98b6    0.332985    0.439841           0.822707  0.787308  0.822707   \n",
       "7cf98922    0.395448    0.381550           0.695639  0.820471  0.695639   \n",
       "b2e4322c    0.329260    0.340102           0.797648  0.833777  0.797648   \n",
       "fa1b3f42    0.323480    0.330400           0.786524  0.845650  0.786524   \n",
       "bfb0d42a    0.428095    0.566273           0.777023  0.780348  0.777023   \n",
       "8e3e14ca    0.520586    0.524892           0.500000  0.755578  0.500000   \n",
       "bd040662    0.326928    0.378585           0.817507  0.809417  0.817507   \n",
       "892694e0    0.327245    0.334970           0.791526  0.839509  0.791526   \n",
       "672a49fe    0.466521    0.442448           0.506700  0.758854  0.506700   \n",
       "321a27b6    0.389036    0.377890           0.678764  0.821085  0.678764   \n",
       "5fa454e6    0.382354    0.368111           0.754909  0.818424  0.754909   \n",
       "5ecb73e2    0.332711    0.331978           0.756741  0.846878  0.756741   \n",
       "\n",
       "                f1    recall  time_this_iter_s  done timesteps_total  ...  \\\n",
       "trial_id                                                              ...   \n",
       "2b1fc86c  0.645846  0.917923         13.669288  True            None  ...   \n",
       "01671fb6  0.655423  0.829983          9.870879  True            None  ...   \n",
       "096db176  0.680926  0.813233          4.054139  True            None  ...   \n",
       "0ae8a390  0.675131  0.645729          4.061585  True            None  ...   \n",
       "e8ec1c22  0.680034  0.667504          4.238353  True            None  ...   \n",
       "c824748a  0.573922  0.468174          3.311373  True            None  ...   \n",
       "4cc02af0  0.585174  0.499162          3.396277  True            None  ...   \n",
       "24384d88  0.642690  0.576214          3.304428  True            None  ...   \n",
       "fce0c562  0.044190  0.022613          4.083665  True            None  ...   \n",
       "c01435b0  0.001674  0.000838          4.090947  True            None  ...   \n",
       "8346556e  0.674738  0.863484          6.387970  True            None  ...   \n",
       "61e56ea0  0.671670  0.899497          6.632267  True            None  ...   \n",
       "69ee27b4  0.681979  0.808208          3.194201  True            None  ...   \n",
       "432f5b20  0.679089  0.686767          4.248960  True            None  ...   \n",
       "22fed74a  0.544336  0.444724          4.075182  True            None  ...   \n",
       "02369e76  0.373200  0.249581          3.234192  True            None  ...   \n",
       "e16de85c  0.667746  0.863484          3.225180  True            None  ...   \n",
       "b7b1f1e8  0.662508  0.889447          3.166104  True            None  ...   \n",
       "5b4e98b6  0.672136  0.891960          4.359169  True            None  ...   \n",
       "7cf98922  0.551407  0.451424          9.767735  True            None  ...   \n",
       "b2e4322c  0.681319  0.726968          5.939143  True            None  ...   \n",
       "fa1b3f42  0.679966  0.670854          3.361481  True            None  ...   \n",
       "bfb0d42a  0.631651  0.770519         20.496814  True            None  ...   \n",
       "8e3e14ca  0.000000  0.000000          5.994438  True            None  ...   \n",
       "bd040662  0.681274  0.833333          5.433620  True            None  ...   \n",
       "892694e0  0.680000  0.697655          3.454464  True            None  ...   \n",
       "672a49fe  0.026446  0.013400          5.404740  True            None  ...   \n",
       "321a27b6  0.522404  0.400335          3.379153  True            None  ...   \n",
       "5fa454e6  0.629336  0.630653          5.291440  True            None  ...   \n",
       "5ecb73e2  0.649485  0.580402          3.654984  True            None  ...   \n",
       "\n",
       "               node_ip  time_since_restore timesteps_since_restore  \\\n",
       "trial_id                                                             \n",
       "2b1fc86c  192.168.1.72          207.305803                       0   \n",
       "01671fb6  192.168.1.72          148.259154                       0   \n",
       "096db176  192.168.1.72           66.586652                       0   \n",
       "0ae8a390  192.168.1.72          412.697139                       0   \n",
       "e8ec1c22  192.168.1.72          423.694614                       0   \n",
       "c824748a  192.168.1.72           52.843226                       0   \n",
       "4cc02af0  192.168.1.72           51.748903                       0   \n",
       "24384d88  192.168.1.72          203.719640                       0   \n",
       "fce0c562  192.168.1.72           63.796139                       0   \n",
       "c01435b0  192.168.1.72           62.767963                       0   \n",
       "8346556e  192.168.1.72           98.831448                       0   \n",
       "61e56ea0  192.168.1.72           98.442428                       0   \n",
       "69ee27b4  192.168.1.72           52.733872                       0   \n",
       "432f5b20  192.168.1.72          412.544340                       0   \n",
       "22fed74a  192.168.1.72           61.070451                       0   \n",
       "02369e76  192.168.1.72           50.556549                       0   \n",
       "e16de85c  192.168.1.72           50.916437                       0   \n",
       "b7b1f1e8  192.168.1.72           51.397341                       0   \n",
       "5b4e98b6  192.168.1.72           66.512451                       0   \n",
       "7cf98922  192.168.1.72          150.971434                       0   \n",
       "b2e4322c  192.168.1.72          369.543921                       0   \n",
       "fa1b3f42  192.168.1.72          335.135817                       0   \n",
       "bfb0d42a  192.168.1.72          306.748746                       0   \n",
       "8e3e14ca  192.168.1.72           94.302230                       0   \n",
       "bd040662  192.168.1.72           79.361793                       0   \n",
       "892694e0  192.168.1.72          346.993001                       0   \n",
       "672a49fe  192.168.1.72           83.761861                       0   \n",
       "321a27b6  192.168.1.72           53.691812                       0   \n",
       "5fa454e6  192.168.1.72           85.386159                       0   \n",
       "5ecb73e2  192.168.1.72          350.885072                       0   \n",
       "\n",
       "         iterations_since_restore  \\\n",
       "trial_id                            \n",
       "2b1fc86c                       15   \n",
       "01671fb6                       15   \n",
       "096db176                       15   \n",
       "0ae8a390                      100   \n",
       "e8ec1c22                      100   \n",
       "c824748a                       15   \n",
       "4cc02af0                       15   \n",
       "24384d88                       60   \n",
       "fce0c562                       15   \n",
       "c01435b0                       15   \n",
       "8346556e                       15   \n",
       "61e56ea0                       15   \n",
       "69ee27b4                       15   \n",
       "432f5b20                      100   \n",
       "22fed74a                       15   \n",
       "02369e76                       15   \n",
       "e16de85c                       15   \n",
       "b7b1f1e8                       15   \n",
       "5b4e98b6                       15   \n",
       "7cf98922                       15   \n",
       "b2e4322c                       60   \n",
       "fa1b3f42                      100   \n",
       "bfb0d42a                       15   \n",
       "8e3e14ca                       15   \n",
       "bd040662                       15   \n",
       "892694e0                      100   \n",
       "672a49fe                       15   \n",
       "321a27b6                       15   \n",
       "5fa454e6                       15   \n",
       "5ecb73e2                      100   \n",
       "\n",
       "                                             experiment_tag  config.n_layers  \\\n",
       "trial_id                                                                       \n",
       "2b1fc86c  30_dropout=0.24116,embedding_size=1024,n_head=...                3   \n",
       "01671fb6  29_dropout=0.23304,embedding_size=1024,n_head=...                2   \n",
       "096db176  28_dropout=0.42651,embedding_size=256,n_head=2...                2   \n",
       "0ae8a390  27_dropout=0.23316,embedding_size=32,n_head=4,...                2   \n",
       "e8ec1c22  26_dropout=0.41023,embedding_size=32,n_head=2,...                2   \n",
       "c824748a  25_dropout=0.39516,embedding_size=32,n_head=2,...                1   \n",
       "4cc02af0  24_dropout=0.15178,embedding_size=32,n_head=32...                1   \n",
       "24384d88  23_dropout=0.15045,embedding_size=32,n_head=32...                1   \n",
       "fce0c562  22_dropout=0.023816,embedding_size=32,n_head=1...                2   \n",
       "c01435b0  21_dropout=0.00010423,embedding_size=32,n_head...                2   \n",
       "8346556e  20_dropout=0.087323,embedding_size=512,n_head=...                3   \n",
       "61e56ea0  19_dropout=0.091955,embedding_size=512,n_head=...                3   \n",
       "69ee27b4  18_dropout=0.23356,embedding_size=128,n_head=2...                1   \n",
       "432f5b20  17_dropout=0.1001,embedding_size=32,n_head=2,n...                2   \n",
       "22fed74a  16_dropout=0.080271,embedding_size=32,n_head=3...                2   \n",
       "02369e76  15_dropout=0.31471,embedding_size=32,n_head=32...                1   \n",
       "e16de85c  14_dropout=0.28096,embedding_size=32,n_head=32...                1   \n",
       "b7b1f1e8  13_dropout=0.18809,embedding_size=32,n_head=32...                1   \n",
       "5b4e98b6  12_dropout=0.16845,embedding_size=128,n_head=8...                2   \n",
       "7cf98922  11_dropout=0.21029,embedding_size=1024,n_head=...                2   \n",
       "b2e4322c  10_dropout=0.47769,embedding_size=32,n_head=16...                4   \n",
       "fa1b3f42  9_dropout=0.21518,embedding_size=32,n_head=32,...                1   \n",
       "bfb0d42a  8_dropout=0.45645,embedding_size=1024,n_head=4...                4   \n",
       "8e3e14ca  7_dropout=0.015357,embedding_size=64,n_head=32...                4   \n",
       "bd040662  6_dropout=0.13216,embedding_size=512,n_head=4,...                2   \n",
       "892694e0  5_dropout=0.49874,embedding_size=64,n_head=1,n...                1   \n",
       "672a49fe  4_dropout=0.28729,embedding_size=256,n_head=16...                3   \n",
       "321a27b6  3_dropout=0.35769,embedding_size=64,n_head=2,n...                1   \n",
       "5fa454e6  2_dropout=0.36136,embedding_size=256,n_head=32...                3   \n",
       "5ecb73e2  1_dropout=0.28353,embedding_size=32,n_head=32,...                1   \n",
       "\n",
       "          config.optimizer__lr config.n_head config.n_hid  config.dropout  \n",
       "trial_id                                                                   \n",
       "2b1fc86c              0.009158             4           32        0.241161  \n",
       "01671fb6              0.011659             4           32        0.233039  \n",
       "096db176              0.002451             2           32        0.426513  \n",
       "0ae8a390              0.002253             4           32        0.233162  \n",
       "e8ec1c22              0.002176             2           32        0.410234  \n",
       "c824748a              0.000752             2          256        0.395155  \n",
       "4cc02af0              0.000733            32          256        0.151776  \n",
       "24384d88              0.000955            32          256        0.150448  \n",
       "fce0c562              0.000094             1           32        0.023816  \n",
       "c01435b0              0.000069             1           32        0.000104  \n",
       "8346556e              0.004962             2           32        0.087323  \n",
       "61e56ea0              0.004543             2           32        0.091955  \n",
       "69ee27b4              0.003717             2         1024        0.233562  \n",
       "432f5b20              0.003176             2           32        0.100098  \n",
       "22fed74a              0.000374            32           32        0.080271  \n",
       "02369e76              0.000339            32           32        0.314713  \n",
       "e16de85c              0.069661            32          128        0.280961  \n",
       "b7b1f1e8              0.039257            32          128        0.188085  \n",
       "5b4e98b6              0.013037             8         1024        0.168447  \n",
       "7cf98922              0.000016             8           64        0.210288  \n",
       "b2e4322c              0.006856            16          512        0.477693  \n",
       "fa1b3f42              0.002616            32           32        0.215179  \n",
       "bfb0d42a              0.020617             4          512        0.456450  \n",
       "8e3e14ca              0.000034            32           32        0.015357  \n",
       "bd040662              0.001354             4          256        0.132163  \n",
       "892694e0              0.002004             1          256        0.498744  \n",
       "672a49fe              0.000027            16          256        0.287286  \n",
       "321a27b6              0.000269             2          512        0.357689  \n",
       "5fa454e6              0.000158            32           64        0.361356  \n",
       "5ecb73e2              0.000934            32          256        0.283534  \n",
       "\n",
       "[30 rows x 28 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis.results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.11 ('DCC-attn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "741e1ea5cc84540885a0ba493c428a89b760d4b9c08bcc57bb2b1068c5ec8401"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
