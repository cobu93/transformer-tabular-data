{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1b19628",
   "metadata": {},
   "source": [
    "# Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d4c4913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:openml.config:No config file found at /home/uriel/.config/openml/config, using default configuration.\n"
     ]
    }
   ],
   "source": [
    "from config import ASSETS_DIR, HYPERPARAMETERS_FILE, DATA_BASE_DIR, SEED, DATASETS_FILE\n",
    "from utils import log, reporting, attention\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "from sklearn import cluster, decomposition, manifold\n",
    "import torch\n",
    "import openml\n",
    "\n",
    "logger = log.get_logger()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42547e49",
   "metadata": {},
   "source": [
    "## General configurations and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5beccf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPTIMIZATION_METRIC = \"log_loss\"\n",
    "OPTIMIZATION_MODE = \"min\"\n",
    "EVALUATION_METRIC = \"balanced_accuracy\"\n",
    "\n",
    "MAPPINGS = {\n",
    "    \"dataset_name\": {\n",
    "            \"jasmine\": \"jasmine\",\n",
    "            \"anneal\": \"anneal\",\n",
    "            \"australian\": \"australian\",\n",
    "            \"kr-vs-kp\": \"kr-vs-kp\",\n",
    "            \"sylvine\": \"sylvine\",\n",
    "            \"nomao\": \"nomao\",\n",
    "            \"volkert\": \"volkert\",\n",
    "            \"adult\": \"adult\",\n",
    "            \"ldpa\": \"ldpa\"\n",
    "        },\n",
    "    \"aggregator_name\": {\n",
    "        \"cls\": \"CLS\",\n",
    "        \"concatenate\": \"CAT\",\n",
    "        \"max\": \"MAX\",\n",
    "        \"mean\": \"AVG\",\n",
    "        \"rnn\": \"RNN\",\n",
    "        \"sum\": \"SUM\",\n",
    "    }\n",
    "}\n",
    "\n",
    "DATASET_ORDER = [\"jasmine\", \"anneal\", \"australian\", \"kr-vs-kp\", \"sylvine\", \"nomao\", \"volkert\", \"adult\", \"ldpa\"]\n",
    "AGGREGATOR_ORDER = [\"CLS\", \"CAT\", \"RNN\", \"MAX\", \"AVG\", \"SUM\"]\n",
    "FEATURE_SELECTION_ORDER = [\"attention\", \"decision_tree\", \"linear_model\", \"f_classif\", \"random\"]\n",
    "    \n",
    "COLORS = [\"#ffc5de\", \"#ffefd8\", \"#c7f7f7\", \"#d1d1d1\", \"#bedfff\", \"#e1c5ff\"]\n",
    "COLORS = plotly.colors.qualitative.Plotly\n",
    "\n",
    "COLORS = [\"rgba({}, {}, {}, 0.8)\".format(*plotly.colors.hex_to_rgb(c)) for c in COLORS ]\n",
    "\n",
    "HP_IMPORTANCE_TOP_K = [1, 5]\n",
    "IMG_SCALE = 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7c6f9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(ASSETS_DIR):\n",
    "    os.makedirs(ASSETS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab6926a",
   "metadata": {},
   "source": [
    "## Best validation models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37c7b0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_as_str(x):\n",
    "    return \"{0:.3f}\".format(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bf43595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>aggregator</th>\n",
       "      <th>architecture_name</th>\n",
       "      <th>attn_dropout</th>\n",
       "      <th>embed_dim</th>\n",
       "      <th>ff_dropout</th>\n",
       "      <th>n_head</th>\n",
       "      <th>n_layers</th>\n",
       "      <th>numerical_passthrough</th>\n",
       "      <th>optimizer__lr</th>\n",
       "      <th>...</th>\n",
       "      <th>log_loss_mean</th>\n",
       "      <th>log_loss_std</th>\n",
       "      <th>roc_auc_mean</th>\n",
       "      <th>roc_auc_std</th>\n",
       "      <th>f1_mean</th>\n",
       "      <th>f1_std</th>\n",
       "      <th>precision_mean</th>\n",
       "      <th>precision_std</th>\n",
       "      <th>recall_mean</th>\n",
       "      <th>recall_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adult</td>\n",
       "      <td>CLS</td>\n",
       "      <td>A0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>128</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.313841</td>\n",
       "      <td>0.005949</td>\n",
       "      <td>0.782128</td>\n",
       "      <td>0.007264</td>\n",
       "      <td>0.905666</td>\n",
       "      <td>0.002347</td>\n",
       "      <td>0.891128</td>\n",
       "      <td>0.004609</td>\n",
       "      <td>0.920736</td>\n",
       "      <td>0.006608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>adult</td>\n",
       "      <td>CLS</td>\n",
       "      <td>A1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>128</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.298849</td>\n",
       "      <td>0.006955</td>\n",
       "      <td>0.786045</td>\n",
       "      <td>0.006501</td>\n",
       "      <td>0.910700</td>\n",
       "      <td>0.002980</td>\n",
       "      <td>0.891587</td>\n",
       "      <td>0.004097</td>\n",
       "      <td>0.930703</td>\n",
       "      <td>0.007685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adult</td>\n",
       "      <td>CLS</td>\n",
       "      <td>A10</td>\n",
       "      <td>0.3</td>\n",
       "      <td>128</td>\n",
       "      <td>0.1</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.316315</td>\n",
       "      <td>0.005494</td>\n",
       "      <td>0.781634</td>\n",
       "      <td>0.011839</td>\n",
       "      <td>0.904706</td>\n",
       "      <td>0.002698</td>\n",
       "      <td>0.891279</td>\n",
       "      <td>0.007803</td>\n",
       "      <td>0.918682</td>\n",
       "      <td>0.010316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adult</td>\n",
       "      <td>CLS</td>\n",
       "      <td>A11</td>\n",
       "      <td>0.3</td>\n",
       "      <td>128</td>\n",
       "      <td>0.1</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.299645</td>\n",
       "      <td>0.006269</td>\n",
       "      <td>0.790115</td>\n",
       "      <td>0.006428</td>\n",
       "      <td>0.910603</td>\n",
       "      <td>0.002414</td>\n",
       "      <td>0.894338</td>\n",
       "      <td>0.004550</td>\n",
       "      <td>0.927537</td>\n",
       "      <td>0.008208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adult</td>\n",
       "      <td>CLS</td>\n",
       "      <td>A12</td>\n",
       "      <td>0.3</td>\n",
       "      <td>128</td>\n",
       "      <td>0.1</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.317639</td>\n",
       "      <td>0.006076</td>\n",
       "      <td>0.781732</td>\n",
       "      <td>0.010861</td>\n",
       "      <td>0.904602</td>\n",
       "      <td>0.002478</td>\n",
       "      <td>0.891367</td>\n",
       "      <td>0.007112</td>\n",
       "      <td>0.918345</td>\n",
       "      <td>0.009063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3067</th>\n",
       "      <td>volkert</td>\n",
       "      <td>SUM</td>\n",
       "      <td>A59</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>0.1</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.986028</td>\n",
       "      <td>0.016224</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3068</th>\n",
       "      <td>volkert</td>\n",
       "      <td>SUM</td>\n",
       "      <td>A61</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>0.1</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.989968</td>\n",
       "      <td>0.018868</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3069</th>\n",
       "      <td>volkert</td>\n",
       "      <td>SUM</td>\n",
       "      <td>A63</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>0.1</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>1.002055</td>\n",
       "      <td>0.019389</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3070</th>\n",
       "      <td>volkert</td>\n",
       "      <td>SUM</td>\n",
       "      <td>A7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>128</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.995919</td>\n",
       "      <td>0.014608</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3071</th>\n",
       "      <td>volkert</td>\n",
       "      <td>SUM</td>\n",
       "      <td>A9</td>\n",
       "      <td>0.3</td>\n",
       "      <td>128</td>\n",
       "      <td>0.1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.976823</td>\n",
       "      <td>0.016513</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3072 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      dataset aggregator architecture_name  attn_dropout  embed_dim  \\\n",
       "0       adult        CLS                A0           0.3        128   \n",
       "1       adult        CLS                A1           0.3        128   \n",
       "2       adult        CLS               A10           0.3        128   \n",
       "3       adult        CLS               A11           0.3        128   \n",
       "4       adult        CLS               A12           0.3        128   \n",
       "...       ...        ...               ...           ...        ...   \n",
       "3067  volkert        SUM               A59           0.3        256   \n",
       "3068  volkert        SUM               A61           0.3        256   \n",
       "3069  volkert        SUM               A63           0.3        256   \n",
       "3070  volkert        SUM                A7           0.3        128   \n",
       "3071  volkert        SUM                A9           0.3        128   \n",
       "\n",
       "      ff_dropout  n_head  n_layers  numerical_passthrough  optimizer__lr  ...  \\\n",
       "0            0.1       4         2                   True         0.0001  ...   \n",
       "1            0.1       4         2                  False         0.0001  ...   \n",
       "2            0.1       8         3                   True         0.0001  ...   \n",
       "3            0.1       8         3                  False         0.0001  ...   \n",
       "4            0.1       8         4                   True         0.0001  ...   \n",
       "...          ...     ...       ...                    ...            ...  ...   \n",
       "3067         0.1      32         3                  False         0.0001  ...   \n",
       "3068         0.1      32         4                  False         0.0001  ...   \n",
       "3069         0.1      32         5                  False         0.0001  ...   \n",
       "3070         0.1       4         5                  False         0.0001  ...   \n",
       "3071         0.1       8         2                  False         0.0001  ...   \n",
       "\n",
       "      log_loss_mean log_loss_std  roc_auc_mean  roc_auc_std   f1_mean  \\\n",
       "0          0.313841     0.005949      0.782128     0.007264  0.905666   \n",
       "1          0.298849     0.006955      0.786045     0.006501  0.910700   \n",
       "2          0.316315     0.005494      0.781634     0.011839  0.904706   \n",
       "3          0.299645     0.006269      0.790115     0.006428  0.910603   \n",
       "4          0.317639     0.006076      0.781732     0.010861  0.904602   \n",
       "...             ...          ...           ...          ...       ...   \n",
       "3067       0.986028     0.016224           NaN          NaN       NaN   \n",
       "3068       0.989968     0.018868           NaN          NaN       NaN   \n",
       "3069       1.002055     0.019389           NaN          NaN       NaN   \n",
       "3070       0.995919     0.014608           NaN          NaN       NaN   \n",
       "3071       0.976823     0.016513           NaN          NaN       NaN   \n",
       "\n",
       "        f1_std  precision_mean  precision_std  recall_mean  recall_std  \n",
       "0     0.002347        0.891128       0.004609     0.920736    0.006608  \n",
       "1     0.002980        0.891587       0.004097     0.930703    0.007685  \n",
       "2     0.002698        0.891279       0.007803     0.918682    0.010316  \n",
       "3     0.002414        0.894338       0.004550     0.927537    0.008208  \n",
       "4     0.002478        0.891367       0.007112     0.918345    0.009063  \n",
       "...        ...             ...            ...          ...         ...  \n",
       "3067       NaN             NaN            NaN          NaN         NaN  \n",
       "3068       NaN             NaN            NaN          NaN         NaN  \n",
       "3069       NaN             NaN            NaN          NaN         NaN  \n",
       "3070       NaN             NaN            NaN          NaN         NaN  \n",
       "3071       NaN             NaN            NaN          NaN         NaN  \n",
       "\n",
       "[3072 rows x 29 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute mean and std for each metric\n",
    "# Compute mean and std for each metric\n",
    "best_archs = pd.read_csv(\"cross_validation_scores.csv\")\n",
    "\n",
    "best_archs[\"dataset\"] = best_archs[\"dataset\"].replace(MAPPINGS[\"dataset_name\"])\n",
    "best_archs[\"aggregator\"] = best_archs[\"aggregator\"].replace(MAPPINGS[\"aggregator_name\"])\n",
    "best_archs[f\"{EVALUATION_METRIC}_mean\"] = best_archs[f\"{EVALUATION_METRIC}_mean\"] * 100\n",
    "best_archs[f\"{EVALUATION_METRIC}_std\"] = best_archs[f\"{EVALUATION_METRIC}_std\"] * 100\n",
    "\n",
    "#assert best_archs.shape[0] == 3072, \"The number of aggregated executions is wrong\"\n",
    "best_archs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ab8ed6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load hyperparameter space\n",
    "with open(HYPERPARAMETERS_FILE, \"r\") as f:\n",
    "    hyperparameters = json.load(f)\n",
    "    \n",
    "hyperparameters = {\n",
    "    **hyperparameters[\"parameters\"],\n",
    "    **hyperparameters[\"rnn_parameters\"],\n",
    "}\n",
    "\n",
    "fixed_hyperparameters = { k: v[0] for k, v in hyperparameters.items() if len(v) == 1 }\n",
    "search_hyperparameters = { k: v for k, v in hyperparameters.items() if len(v) > 1 }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54850230",
   "metadata": {},
   "source": [
    "### Per dataset & aggregator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65a19f2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>CLS</th>\n",
       "      <th>CAT</th>\n",
       "      <th>RNN</th>\n",
       "      <th>MAX</th>\n",
       "      <th>AVG</th>\n",
       "      <th>SUM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jasmine</td>\n",
       "      <td>$81.201 \\pm 1.161$</td>\n",
       "      <td>$80.352 \\pm 1.511$</td>\n",
       "      <td>$82.381 \\pm 0.795$</td>\n",
       "      <td>$81.763 \\pm 1.771$</td>\n",
       "      <td>$81.421 \\pm 1.468$</td>\n",
       "      <td>$80.560 \\pm 1.277$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anneal</td>\n",
       "      <td>$95.677 \\pm 8.887$</td>\n",
       "      <td>$95.260 \\pm 8.680$</td>\n",
       "      <td>$90.594 \\pm 11.434$</td>\n",
       "      <td>$91.224 \\pm 10.439$</td>\n",
       "      <td>$91.391 \\pm 11.575$</td>\n",
       "      <td>$90.477 \\pm 10.815$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>australian</td>\n",
       "      <td>$85.082 \\pm 2.604$</td>\n",
       "      <td>$86.107 \\pm 3.312$</td>\n",
       "      <td>$85.565 \\pm 3.405$</td>\n",
       "      <td>$86.261 \\pm 3.544$</td>\n",
       "      <td>$86.008 \\pm 3.801$</td>\n",
       "      <td>$86.679 \\pm 2.629$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kr-vs-kp</td>\n",
       "      <td>$99.802 \\pm 0.245$</td>\n",
       "      <td>$99.884 \\pm 0.169$</td>\n",
       "      <td>$99.649 \\pm 0.167$</td>\n",
       "      <td>$99.760 \\pm 0.219$</td>\n",
       "      <td>$99.756 \\pm 0.168$</td>\n",
       "      <td>$99.715 \\pm 0.108$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sylvine</td>\n",
       "      <td>$94.890 \\pm 0.404$</td>\n",
       "      <td>$94.110 \\pm 0.327$</td>\n",
       "      <td>$94.621 \\pm 0.632$</td>\n",
       "      <td>$94.524 \\pm 0.454$</td>\n",
       "      <td>$94.276 \\pm 0.714$</td>\n",
       "      <td>$94.060 \\pm 0.493$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nomao</td>\n",
       "      <td>$95.075 \\pm 0.247$</td>\n",
       "      <td>$93.867 \\pm 0.556$</td>\n",
       "      <td>$94.121 \\pm 0.482$</td>\n",
       "      <td>$94.472 \\pm 0.543$</td>\n",
       "      <td>$94.738 \\pm 0.404$</td>\n",
       "      <td>$93.472 \\pm 0.996$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>volkert</td>\n",
       "      <td>$61.911 \\pm 0.487$</td>\n",
       "      <td>$56.803 \\pm 0.580$</td>\n",
       "      <td>$60.847 \\pm 0.879$</td>\n",
       "      <td>$60.319 \\pm 0.381$</td>\n",
       "      <td>$59.238 \\pm 0.503$</td>\n",
       "      <td>$57.954 \\pm 1.138$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adult</td>\n",
       "      <td>$78.604 \\pm 0.650$</td>\n",
       "      <td>$79.006 \\pm 1.302$</td>\n",
       "      <td>$79.007 \\pm 1.168$</td>\n",
       "      <td>$78.759 \\pm 1.269$</td>\n",
       "      <td>$78.900 \\pm 1.124$</td>\n",
       "      <td>$78.311 \\pm 1.142$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ldpa</td>\n",
       "      <td>$56.023 \\pm 0.431$</td>\n",
       "      <td>$56.351 \\pm 0.988$</td>\n",
       "      <td>$54.952 \\pm 0.527$</td>\n",
       "      <td>$56.847 \\pm 1.147$</td>\n",
       "      <td>$54.885 \\pm 0.641$</td>\n",
       "      <td>$55.641 \\pm 0.753$</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              CLS                 CAT                  RNN  \\\n",
       "3     jasmine  $81.201 \\pm 1.161$  $80.352 \\pm 1.511$   $82.381 \\pm 0.795$   \n",
       "1      anneal  $95.677 \\pm 8.887$  $95.260 \\pm 8.680$  $90.594 \\pm 11.434$   \n",
       "2  australian  $85.082 \\pm 2.604$  $86.107 \\pm 3.312$   $85.565 \\pm 3.405$   \n",
       "4    kr-vs-kp  $99.802 \\pm 0.245$  $99.884 \\pm 0.169$   $99.649 \\pm 0.167$   \n",
       "7     sylvine  $94.890 \\pm 0.404$  $94.110 \\pm 0.327$   $94.621 \\pm 0.632$   \n",
       "6       nomao  $95.075 \\pm 0.247$  $93.867 \\pm 0.556$   $94.121 \\pm 0.482$   \n",
       "8     volkert  $61.911 \\pm 0.487$  $56.803 \\pm 0.580$   $60.847 \\pm 0.879$   \n",
       "0       adult  $78.604 \\pm 0.650$  $79.006 \\pm 1.302$   $79.007 \\pm 1.168$   \n",
       "5        ldpa  $56.023 \\pm 0.431$  $56.351 \\pm 0.988$   $54.952 \\pm 0.527$   \n",
       "\n",
       "                   MAX                  AVG                  SUM  \n",
       "3   $81.763 \\pm 1.771$   $81.421 \\pm 1.468$   $80.560 \\pm 1.277$  \n",
       "1  $91.224 \\pm 10.439$  $91.391 \\pm 11.575$  $90.477 \\pm 10.815$  \n",
       "2   $86.261 \\pm 3.544$   $86.008 \\pm 3.801$   $86.679 \\pm 2.629$  \n",
       "4   $99.760 \\pm 0.219$   $99.756 \\pm 0.168$   $99.715 \\pm 0.108$  \n",
       "7   $94.524 \\pm 0.454$   $94.276 \\pm 0.714$   $94.060 \\pm 0.493$  \n",
       "6   $94.472 \\pm 0.543$   $94.738 \\pm 0.404$   $93.472 \\pm 0.996$  \n",
       "8   $60.319 \\pm 0.381$   $59.238 \\pm 0.503$   $57.954 \\pm 1.138$  \n",
       "0   $78.759 \\pm 1.269$   $78.900 \\pm 1.124$   $78.311 \\pm 1.142$  \n",
       "5   $56.847 \\pm 1.147$   $54.885 \\pm 0.641$   $55.641 \\pm 0.753$  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get registers with the lowest optimization metric\n",
    "best_archs_ds_agg = best_archs.loc[reporting.get_top_k_indices(\n",
    "                                        best_archs.groupby([\"dataset\", \"aggregator\"]),\n",
    "                                        1,\n",
    "                                        f\"{OPTIMIZATION_METRIC}_mean\",\n",
    "                                        OPTIMIZATION_MODE\n",
    "                                        )\n",
    "                                  ]\n",
    "\n",
    "#assert best_archs_ds_agg.shape[0] == 54, \"The number of optimal architectures is wrong\"\n",
    "\n",
    "\n",
    "# Adds a column to format Latex\n",
    "best_archs_ds_agg[EVALUATION_METRIC] = \"$\" + best_archs_ds_agg[f\"{EVALUATION_METRIC}_mean\"].apply(num_as_str) \\\n",
    "                                + \" \\pm \" + best_archs_ds_agg[f\"{EVALUATION_METRIC}_std\"].apply(num_as_str) + \"$\"\n",
    "\n",
    "# Exports best dataset-aggregator configuration\n",
    "\n",
    "best_archs_ds_agg = best_archs_ds_agg[[\"dataset\", \"aggregator\", EVALUATION_METRIC]] \\\n",
    "                        .pivot(index=\"dataset\", columns=\"aggregator\") \\\n",
    "                        .reset_index()\n",
    "best_archs_ds_agg.columns = [col[1] for col in best_archs_ds_agg.columns]\n",
    "\n",
    "best_archs_ds_agg = best_archs_ds_agg.sort_values(\"\", key=lambda x: x.apply(DATASET_ORDER.index))\n",
    "best_archs_ds_agg = best_archs_ds_agg[[\"\"] + AGGREGATOR_ORDER]\n",
    "\n",
    "with open(os.path.join(ASSETS_DIR, \"ds_agg_baccuracy_cv.tex\"), \"w\") as f:\n",
    "    f.write(best_archs_ds_agg.to_latex(index=False))\n",
    "    \n",
    "best_archs_ds_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "edb90505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>CLS</th>\n",
       "      <th>CAT</th>\n",
       "      <th>RNN</th>\n",
       "      <th>MAX</th>\n",
       "      <th>AVG</th>\n",
       "      <th>SUM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jasmine</td>\n",
       "      <td>$0.406 \\pm 0.025$</td>\n",
       "      <td>$0.415 \\pm 0.025$</td>\n",
       "      <td>$0.401 \\pm 0.022$</td>\n",
       "      <td>$0.408 \\pm 0.035$</td>\n",
       "      <td>$0.414 \\pm 0.036$</td>\n",
       "      <td>$0.417 \\pm 0.033$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anneal</td>\n",
       "      <td>$0.033 \\pm 0.048$</td>\n",
       "      <td>$0.022 \\pm 0.025$</td>\n",
       "      <td>$0.033 \\pm 0.029$</td>\n",
       "      <td>$0.030 \\pm 0.023$</td>\n",
       "      <td>$0.030 \\pm 0.027$</td>\n",
       "      <td>$0.028 \\pm 0.018$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>australian</td>\n",
       "      <td>$0.318 \\pm 0.054$</td>\n",
       "      <td>$0.323 \\pm 0.055$</td>\n",
       "      <td>$0.332 \\pm 0.052$</td>\n",
       "      <td>$0.323 \\pm 0.051$</td>\n",
       "      <td>$0.329 \\pm 0.061$</td>\n",
       "      <td>$0.318 \\pm 0.060$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kr-vs-kp</td>\n",
       "      <td>$0.005 \\pm 0.005$</td>\n",
       "      <td>$0.005 \\pm 0.004$</td>\n",
       "      <td>$0.008 \\pm 0.004$</td>\n",
       "      <td>$0.006 \\pm 0.005$</td>\n",
       "      <td>$0.006 \\pm 0.004$</td>\n",
       "      <td>$0.006 \\pm 0.002$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sylvine</td>\n",
       "      <td>$0.147 \\pm 0.009$</td>\n",
       "      <td>$0.164 \\pm 0.013$</td>\n",
       "      <td>$0.154 \\pm 0.015$</td>\n",
       "      <td>$0.164 \\pm 0.013$</td>\n",
       "      <td>$0.161 \\pm 0.014$</td>\n",
       "      <td>$0.170 \\pm 0.013$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nomao</td>\n",
       "      <td>$0.097 \\pm 0.004$</td>\n",
       "      <td>$0.111 \\pm 0.008$</td>\n",
       "      <td>$0.106 \\pm 0.004$</td>\n",
       "      <td>$0.102 \\pm 0.008$</td>\n",
       "      <td>$0.105 \\pm 0.005$</td>\n",
       "      <td>$0.111 \\pm 0.009$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>volkert</td>\n",
       "      <td>$0.888 \\pm 0.012$</td>\n",
       "      <td>$0.977 \\pm 0.013$</td>\n",
       "      <td>$0.923 \\pm 0.010$</td>\n",
       "      <td>$0.925 \\pm 0.015$</td>\n",
       "      <td>$0.954 \\pm 0.008$</td>\n",
       "      <td>$0.968 \\pm 0.011$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adult</td>\n",
       "      <td>$0.299 \\pm 0.007$</td>\n",
       "      <td>$0.301 \\pm 0.004$</td>\n",
       "      <td>$0.299 \\pm 0.006$</td>\n",
       "      <td>$0.299 \\pm 0.005$</td>\n",
       "      <td>$0.299 \\pm 0.007$</td>\n",
       "      <td>$0.301 \\pm 0.005$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ldpa</td>\n",
       "      <td>$0.638 \\pm 0.008$</td>\n",
       "      <td>$0.648 \\pm 0.012$</td>\n",
       "      <td>$0.682 \\pm 0.006$</td>\n",
       "      <td>$0.649 \\pm 0.014$</td>\n",
       "      <td>$0.663 \\pm 0.011$</td>\n",
       "      <td>$0.674 \\pm 0.017$</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             CLS                CAT                RNN  \\\n",
       "3     jasmine  $0.406 \\pm 0.025$  $0.415 \\pm 0.025$  $0.401 \\pm 0.022$   \n",
       "1      anneal  $0.033 \\pm 0.048$  $0.022 \\pm 0.025$  $0.033 \\pm 0.029$   \n",
       "2  australian  $0.318 \\pm 0.054$  $0.323 \\pm 0.055$  $0.332 \\pm 0.052$   \n",
       "4    kr-vs-kp  $0.005 \\pm 0.005$  $0.005 \\pm 0.004$  $0.008 \\pm 0.004$   \n",
       "7     sylvine  $0.147 \\pm 0.009$  $0.164 \\pm 0.013$  $0.154 \\pm 0.015$   \n",
       "6       nomao  $0.097 \\pm 0.004$  $0.111 \\pm 0.008$  $0.106 \\pm 0.004$   \n",
       "8     volkert  $0.888 \\pm 0.012$  $0.977 \\pm 0.013$  $0.923 \\pm 0.010$   \n",
       "0       adult  $0.299 \\pm 0.007$  $0.301 \\pm 0.004$  $0.299 \\pm 0.006$   \n",
       "5        ldpa  $0.638 \\pm 0.008$  $0.648 \\pm 0.012$  $0.682 \\pm 0.006$   \n",
       "\n",
       "                 MAX                AVG                SUM  \n",
       "3  $0.408 \\pm 0.035$  $0.414 \\pm 0.036$  $0.417 \\pm 0.033$  \n",
       "1  $0.030 \\pm 0.023$  $0.030 \\pm 0.027$  $0.028 \\pm 0.018$  \n",
       "2  $0.323 \\pm 0.051$  $0.329 \\pm 0.061$  $0.318 \\pm 0.060$  \n",
       "4  $0.006 \\pm 0.005$  $0.006 \\pm 0.004$  $0.006 \\pm 0.002$  \n",
       "7  $0.164 \\pm 0.013$  $0.161 \\pm 0.014$  $0.170 \\pm 0.013$  \n",
       "6  $0.102 \\pm 0.008$  $0.105 \\pm 0.005$  $0.111 \\pm 0.009$  \n",
       "8  $0.925 \\pm 0.015$  $0.954 \\pm 0.008$  $0.968 \\pm 0.011$  \n",
       "0  $0.299 \\pm 0.005$  $0.299 \\pm 0.007$  $0.301 \\pm 0.005$  \n",
       "5  $0.649 \\pm 0.014$  $0.663 \\pm 0.011$  $0.674 \\pm 0.017$  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get registers with the lowest optimization metric\n",
    "best_archs_ds_agg = best_archs.loc[reporting.get_top_k_indices(\n",
    "                                        best_archs.groupby([\"dataset\", \"aggregator\"]),\n",
    "                                        1,\n",
    "                                        f\"{OPTIMIZATION_METRIC}_mean\",\n",
    "                                        OPTIMIZATION_MODE\n",
    "                                        )\n",
    "                                  ]\n",
    "\n",
    "#assert best_archs_ds_agg.shape[0] == 54, \"The number of optimal architectures is wrong\"\n",
    "\n",
    "\n",
    "# Adds a column to format Latex\n",
    "best_archs_ds_agg[OPTIMIZATION_METRIC] = \"$\" + best_archs_ds_agg[f\"{OPTIMIZATION_METRIC}_mean\"].apply(num_as_str) \\\n",
    "                                + \" \\pm \" + best_archs_ds_agg[f\"{OPTIMIZATION_METRIC}_std\"].apply(num_as_str) + \"$\"\n",
    "\n",
    "# Exports best dataset-aggregator configuration\n",
    "\n",
    "best_archs_ds_agg = best_archs_ds_agg[[\"dataset\", \"aggregator\", OPTIMIZATION_METRIC]] \\\n",
    "                        .pivot(index=\"dataset\", columns=\"aggregator\") \\\n",
    "                        .reset_index()\n",
    "best_archs_ds_agg.columns = [col[1] for col in best_archs_ds_agg.columns]\n",
    "\n",
    "best_archs_ds_agg = best_archs_ds_agg.sort_values(\"\", key=lambda x: x.apply(DATASET_ORDER.index))\n",
    "best_archs_ds_agg = best_archs_ds_agg[[\"\"] + AGGREGATOR_ORDER]\n",
    "\n",
    "with open(os.path.join(ASSETS_DIR, \"ds_agg_opt_cv.tex\"), \"w\") as f:\n",
    "    f.write(best_archs_ds_agg.to_latex(index=False))\n",
    "    \n",
    "best_archs_ds_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bced51",
   "metadata": {},
   "source": [
    "### Per dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fafbc74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>aggregator</th>\n",
       "      <th>n_layers</th>\n",
       "      <th>n_head</th>\n",
       "      <th>embed_dim</th>\n",
       "      <th>numerical_passthrough</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1441</th>\n",
       "      <td>jasmine</td>\n",
       "      <td>RNN</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>256</td>\n",
       "      <td>False</td>\n",
       "      <td>$82.381 \\pm 0.795$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>anneal</td>\n",
       "      <td>CAT</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>256</td>\n",
       "      <td>False</td>\n",
       "      <td>$95.260 \\pm 8.680$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117</th>\n",
       "      <td>australian</td>\n",
       "      <td>SUM</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>256</td>\n",
       "      <td>False</td>\n",
       "      <td>$86.679 \\pm 2.629$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1633</th>\n",
       "      <td>kr-vs-kp</td>\n",
       "      <td>CAT</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>256</td>\n",
       "      <td>False</td>\n",
       "      <td>$99.884 \\pm 0.169$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2712</th>\n",
       "      <td>sylvine</td>\n",
       "      <td>CLS</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>256</td>\n",
       "      <td>False</td>\n",
       "      <td>$94.890 \\pm 0.404$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2348</th>\n",
       "      <td>nomao</td>\n",
       "      <td>CLS</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>256</td>\n",
       "      <td>False</td>\n",
       "      <td>$95.075 \\pm 0.247$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2880</th>\n",
       "      <td>volkert</td>\n",
       "      <td>CLS</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>128</td>\n",
       "      <td>False</td>\n",
       "      <td>$61.911 \\pm 0.487$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>adult</td>\n",
       "      <td>CLS</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>128</td>\n",
       "      <td>False</td>\n",
       "      <td>$78.604 \\pm 0.650$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1945</th>\n",
       "      <td>ldpa</td>\n",
       "      <td>CLS</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>128</td>\n",
       "      <td>False</td>\n",
       "      <td>$56.023 \\pm 0.431$</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         dataset aggregator  n_layers  n_head  embed_dim  \\\n",
       "1441     jasmine        RNN         5       4        256   \n",
       "479       anneal        CAT         4       4        256   \n",
       "1117  australian        SUM         3       4        256   \n",
       "1633    kr-vs-kp        CAT         5       4        256   \n",
       "2712     sylvine        CLS         4      16        256   \n",
       "2348       nomao        CLS         2      16        256   \n",
       "2880     volkert        CLS         2       4        128   \n",
       "1          adult        CLS         2       4        128   \n",
       "1945        ldpa        CLS         5      32        128   \n",
       "\n",
       "      numerical_passthrough   balanced_accuracy  \n",
       "1441                  False  $82.381 \\pm 0.795$  \n",
       "479                   False  $95.260 \\pm 8.680$  \n",
       "1117                  False  $86.679 \\pm 2.629$  \n",
       "1633                  False  $99.884 \\pm 0.169$  \n",
       "2712                  False  $94.890 \\pm 0.404$  \n",
       "2348                  False  $95.075 \\pm 0.247$  \n",
       "2880                  False  $61.911 \\pm 0.487$  \n",
       "1                     False  $78.604 \\pm 0.650$  \n",
       "1945                  False  $56.023 \\pm 0.431$  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exports best dataset configuration\n",
    "best_archs_ds = best_archs.loc[reporting.get_top_k_indices(\n",
    "                                        best_archs.groupby([\"dataset\"]),\n",
    "                                        1,\n",
    "                                        f\"{OPTIMIZATION_METRIC}_mean\",\n",
    "                                        OPTIMIZATION_MODE\n",
    "                                        )\n",
    "                                  ]\n",
    "\n",
    "#assert best_archs_ds.shape[0] == 9, \"The number of optimal architectures is wrong\"\n",
    "\n",
    "\n",
    "# Adds a column to format Latex\n",
    "best_archs_ds[EVALUATION_METRIC] = \"$\" + best_archs_ds[f\"{EVALUATION_METRIC}_mean\"].apply(num_as_str) \\\n",
    "                                + \" \\pm \" + best_archs_ds[f\"{EVALUATION_METRIC}_std\"].apply(num_as_str) + \"$\"\n",
    "\n",
    "# Exports best dataset configuration\n",
    "best_archs_ds = best_archs_ds[[\"dataset\", \"aggregator\"] + list(search_hyperparameters.keys()) + [EVALUATION_METRIC]]\n",
    "\n",
    "best_archs_ds = best_archs_ds.sort_values(\"dataset\", key=lambda x: x.apply(DATASET_ORDER.index))\n",
    "\n",
    "with open(os.path.join(ASSETS_DIR, \"ds_baccuracy_cv.tex\"), \"w\") as f:\n",
    "    f.write(best_archs_ds.drop(EVALUATION_METRIC, axis=1).to_latex(index=False))\n",
    "\n",
    "best_archs_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b18ee9-413b-4447-b309-448ac57ea2a7",
   "metadata": {},
   "source": [
    "## Best test models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e71b057-d9ae-4e40-8557-5fdd89db49c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>balanced_accuracy_test_report</th>\n",
       "      <th>tt_degradation</th>\n",
       "      <th>tabnet_degradation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jasmine</td>\n",
       "      <td>$79.544 \\pm 2.100$</td>\n",
       "      <td>1.244%</td>\n",
       "      <td>4.787%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anneal</td>\n",
       "      <td>$99.636 \\pm 0.813$</td>\n",
       "      <td>-11.612%</td>\n",
       "      <td>5.626%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>australian</td>\n",
       "      <td>$87.901 \\pm 2.752$</td>\n",
       "      <td>2.024%</td>\n",
       "      <td>4.948%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kr-vs-kp</td>\n",
       "      <td>$99.593 \\pm 0.207$</td>\n",
       "      <td>0.257%</td>\n",
       "      <td>6.610%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sylvine</td>\n",
       "      <td>$95.202 \\pm 0.356$</td>\n",
       "      <td>0.321%</td>\n",
       "      <td>12.474%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nomao</td>\n",
       "      <td>$94.644 \\pm 0.496$</td>\n",
       "      <td>2.646%</td>\n",
       "      <td>1.843%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>volkert</td>\n",
       "      <td>$56.147 \\pm 0.853$</td>\n",
       "      <td>21.655%</td>\n",
       "      <td>17.104%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adult</td>\n",
       "      <td>$78.223 \\pm 0.119$</td>\n",
       "      <td>5.119%</td>\n",
       "      <td>6.414%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ldpa</td>\n",
       "      <td>$50.292 \\pm 0.545$</td>\n",
       "      <td>49.204%</td>\n",
       "      <td>44.636%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      dataset balanced_accuracy_test_report tt_degradation tabnet_degradation\n",
       "3     jasmine            $79.544 \\pm 2.100$         1.244%             4.787%\n",
       "1      anneal            $99.636 \\pm 0.813$       -11.612%             5.626%\n",
       "2  australian            $87.901 \\pm 2.752$         2.024%             4.948%\n",
       "4    kr-vs-kp            $99.593 \\pm 0.207$         0.257%             6.610%\n",
       "7     sylvine            $95.202 \\pm 0.356$         0.321%            12.474%\n",
       "6       nomao            $94.644 \\pm 0.496$         2.646%             1.843%\n",
       "8     volkert            $56.147 \\pm 0.853$        21.655%            17.104%\n",
       "0       adult            $78.223 \\pm 0.119$         5.119%             6.414%\n",
       "5        ldpa            $50.292 \\pm 0.545$        49.204%            44.636%"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_reported_results = {\n",
    "    \"jasmine\": 80.546,\n",
    "    \"anneal\": 89.270,\n",
    "    \"australian\": 89.717,\n",
    "    \"kr-vs-kp\": 99.850,\n",
    "    \"sylvine\": 95.509,\n",
    "    \"nomao\": 97.217,\n",
    "    \"volkert\": 71.667,\n",
    "    \"adult\": 82.443,\n",
    "    \"ldpa\": 99.008,\n",
    "}\n",
    "\n",
    "tabnet_reported_results = {\n",
    "    \"jasmine\": 76.690,\n",
    "    \"anneal\": 84.248,\n",
    "    \"australian\": 85.278,\n",
    "    \"kr-vs-kp\": 93.250,\n",
    "    \"sylvine\": 83.595,\n",
    "    \"nomao\": 95.425,\n",
    "    \"volkert\": 59.409,\n",
    "    \"adult\": 77.155,\n",
    "    \"ldpa\": 54.815,\n",
    "}\n",
    "\n",
    "best_archs_test = pd.read_csv(\"selected_architectures.csv\")\n",
    "best_archs_test[\"dataset\"] = best_archs_test[\"dataset\"].replace(MAPPINGS[\"dataset_name\"])\n",
    "best_archs_test[\"aggregator\"] = best_archs_test[\"aggregator\"].replace(MAPPINGS[\"aggregator_name\"])\n",
    "best_archs_test = best_archs_test.query(\"selection_metric == @OPTIMIZATION_METRIC\")\n",
    "best_archs_test[f\"{EVALUATION_METRIC}_test_mean\"] = best_archs_test[f\"{EVALUATION_METRIC}_test_mean\"] * 100\n",
    "best_archs_test[f\"{EVALUATION_METRIC}_test_std\"] = best_archs_test[f\"{EVALUATION_METRIC}_test_std\"] * 100\n",
    "best_archs_test[f\"{EVALUATION_METRIC}_test_max\"] = (best_archs_test[f\"{EVALUATION_METRIC}_test_max\"] * 100).apply(num_as_str)\n",
    "best_archs_test[f\"{EVALUATION_METRIC}_test_min\"] = (best_archs_test[f\"{EVALUATION_METRIC}_test_min\"] * 100).apply(num_as_str)\n",
    "best_archs_test = best_archs_test.sort_values(\"dataset\", key=lambda x: x.apply(DATASET_ORDER.index))\n",
    "\n",
    "best_reported_results_keys = sorted(best_reported_results, key=lambda x: DATASET_ORDER.index(x))\n",
    "tabnet_reported_results_keys = sorted(tabnet_reported_results, key=lambda x: DATASET_ORDER.index(x))\n",
    "\n",
    "best_reported_results = [best_reported_results[k] for k in best_reported_results_keys ]\n",
    "tabnet_reported_results = [tabnet_reported_results[k] for k in tabnet_reported_results_keys ]\n",
    "\n",
    "best_archs_test[\"best_reported\"] = best_reported_results\n",
    "best_archs_test[\"tabnet_reported\"] = tabnet_reported_results\n",
    "\n",
    "best_archs_test[\"degradation_ratio\"] = 1 - best_archs_test[f\"{EVALUATION_METRIC}_test_mean\"] / best_archs_test[\"best_reported\"]\n",
    "\n",
    "best_archs_test[\"tt_degradation\"] = (best_archs_test[\"degradation_ratio\"] * 100).apply(num_as_str) + \"%\"\n",
    "best_archs_test[\"tabnet_degradation\"] = (100 - best_archs_test[\"tabnet_reported\"] / best_archs_test[\"best_reported\"] * 100).apply(num_as_str) + \"%\"\n",
    "\n",
    "\n",
    "best_archs_test[f\"{EVALUATION_METRIC}_test_report\"] = \"$\" + best_archs_test[f\"{EVALUATION_METRIC}_test_mean\"].apply(num_as_str) \\\n",
    "                                + \" \\pm \" + best_archs_test[f\"{EVALUATION_METRIC}_test_std\"].apply(num_as_str) + \"$\"\n",
    "\n",
    "best_archs_test[[\"dataset\", f\"{EVALUATION_METRIC}_test_report\", \"tt_degradation\", \"tabnet_degradation\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d14f912",
   "metadata": {},
   "source": [
    "### Degradation correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19895114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:Computing datasets features\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>degradation_ratio_pearson</th>\n",
       "      <th>degradation_ratio_spearman</th>\n",
       "      <th>degradation_ratio_kendall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>features_instances</th>\n",
       "      <td>-0.521788</td>\n",
       "      <td>-0.800000</td>\n",
       "      <td>-0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>percent_numerical</th>\n",
       "      <td>0.452824</td>\n",
       "      <td>0.529430</td>\n",
       "      <td>0.400163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>percent_missing_values</th>\n",
       "      <td>-0.414419</td>\n",
       "      <td>-0.273861</td>\n",
       "      <td>-0.215166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>degradation_ratio</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        degradation_ratio_pearson  degradation_ratio_spearman  \\\n",
       "features_instances                      -0.521788                   -0.800000   \n",
       "percent_numerical                        0.452824                    0.529430   \n",
       "percent_missing_values                  -0.414419                   -0.273861   \n",
       "degradation_ratio                        1.000000                    1.000000   \n",
       "\n",
       "                        degradation_ratio_kendall  \n",
       "features_instances                      -0.666667  \n",
       "percent_numerical                        0.400163  \n",
       "percent_missing_values                  -0.215166  \n",
       "degradation_ratio                        1.000000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets_df = pd.read_csv(DATASETS_FILE)\n",
    "datasets = openml.datasets.get_datasets(dataset_ids=datasets_df[\"openml_id\"].values.tolist(), download_data=False)\n",
    "assert np.all(datasets_df[\"n_categorical\"].values == np.array([len(ds.get_features_by_type(\"nominal\")) + len(ds.get_features_by_type(\"string\")) for ds in datasets]))\n",
    "\n",
    "# Compute the metadata for datasets clustering\n",
    "logger.info(\"Computing datasets features\")\n",
    "datasets_df[\"features_instances\"] = datasets_df[\"n_features\"] / datasets_df[\"n_instances\"]\n",
    "datasets_df[\"percent_numerical\"] = datasets_df[\"n_numerical\"] / (datasets_df[\"n_features\"] - 1)\n",
    "datasets_df[\"percent_missing_values\"] =  datasets_df[\"n_missing_values\"] / ((datasets_df[\"n_numerical\"] + datasets_df[\"n_categorical\"] - 1) * datasets_df[\"n_instances\"])\n",
    "\n",
    "# Clustering datasets\n",
    "datasets_df = datasets_df.query(\"name in @DATASET_ORDER\")\n",
    "datasets_df = best_archs_test[[\"dataset\", \"degradation_ratio\"]].merge(\n",
    "                            datasets_df[[\"name\", \"features_instances\", \"percent_numerical\", \"percent_missing_values\"]], \n",
    "                            left_on=\"dataset\", \n",
    "                            right_on=\"name\"\n",
    "                )\n",
    "\n",
    "corr_pearson = datasets_df[[\"features_instances\", \"percent_numerical\", \"percent_missing_values\", \"degradation_ratio\"]] \\\n",
    "        .corr(method=\"pearson\")[[\"degradation_ratio\"]]\n",
    "corr_kendall = datasets_df[[\"features_instances\", \"percent_numerical\", \"percent_missing_values\", \"degradation_ratio\"]] \\\n",
    "        .corr(method=\"kendall\")[[\"degradation_ratio\"]]\n",
    "corr_spearman = datasets_df[[\"features_instances\", \"percent_numerical\", \"percent_missing_values\", \"degradation_ratio\"]] \\\n",
    "        .corr(method=\"spearman\")[[\"degradation_ratio\"]]\n",
    "corr = pd.concat([corr_pearson, corr_spearman, corr_kendall], axis=1)\n",
    "corr.columns = [\"degradation_ratio_pearson\", \"degradation_ratio_spearman\", \"degradation_ratio_kendall\"]\n",
    "corr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76035bbb",
   "metadata": {},
   "source": [
    "## Hyperparameters importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec36e840",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_map = {}\n",
    "color_map[\"aggregator\"] = { agg: color for agg, color in zip(MAPPINGS[\"aggregator_name\"].values(), COLORS) }\n",
    "\n",
    "for k, v in search_hyperparameters.items():\n",
    "    color_map[k] = {agg: color for agg, color in zip(v, COLORS) }\n",
    "    \n",
    "label_map = {\n",
    "    \"aggregator\": \"{}\",\n",
    "    \"n_layers\": \"{} layers\",\n",
    "    \"n_head\": \"{} heads\",\n",
    "    \"embed_dim\": \"{} dims\",\n",
    "    \"numerical_passthrough\": \"{}\"    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c47ba01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "layout = go.Layout(\n",
    "    margin={\"l\": 0, \"r\": 0, \"b\": 0, \"t\": 0},    \n",
    "    template=\"plotly_white\",\n",
    "    font={\"size\": 22}\n",
    ")\n",
    "\n",
    "for top_k_value in HP_IMPORTANCE_TOP_K:\n",
    "\n",
    "    best_archs_indices = reporting.get_top_k_indices(\n",
    "        best_archs.groupby([\"dataset\"]),\n",
    "        top_k_value,\n",
    "        f\"{OPTIMIZATION_METRIC}_mean\",\n",
    "        OPTIMIZATION_MODE\n",
    "    )\n",
    "\n",
    "    #assert len(best_archs_indices) == 9 * top_k_value, \"Best architectures indices got wrong\"\n",
    "    \n",
    "    top_k_archs_df = best_archs[[\"aggregator\"] + list(search_hyperparameters.keys()) ].loc[best_archs_indices]\n",
    "    \n",
    "    for c in top_k_archs_df.columns:\n",
    "        \n",
    "        labels = []\n",
    "        values = []\n",
    "        \n",
    "        for prop, value in top_k_archs_df[c].value_counts(normalize=True).items():\n",
    "            labels.append(prop)\n",
    "            values.append(value)\n",
    "            \n",
    "        common_props = dict(\n",
    "                            labels=[label_map[c].format(l) for l in labels], \n",
    "                            values=values, \n",
    "                            showlegend=False\n",
    "                        )\n",
    "        \n",
    "        label_trace = go.Pie(**common_props, textinfo=\"label\", textposition=\"outside\")\n",
    "        percent_trace = go.Pie(**common_props, textinfo=\"percent\", textposition=\"inside\")\n",
    "            \n",
    "        fig = go.Figure(data=[label_trace, percent_trace], layout=layout)\n",
    "        fig.update_traces(\n",
    "            marker=dict(\n",
    "                    colors=[color_map[c][l] for l in labels]\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        fig.write_image(os.path.join(ASSETS_DIR, f\"t{top_k_value}_{c}_importance.png\"), scale=IMG_SCALE)\n",
    "        \n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1fc8bd",
   "metadata": {},
   "source": [
    "## Cumulative attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36ddcb6c-36d0-464b-96f4-9b359633fcaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_attention_with_meta(dataset, selection_metric):\n",
    "    data_dir = os.path.join(DATA_BASE_DIR, dataset)\n",
    "    attention_file = os.path.join(data_dir, \"feature_selection_cluster_fmask\", selection_metric, \"attention.npy\")\n",
    "    attention_file_info = os.path.join(data_dir, \"feature_selection_cluster_fmask\", selection_metric, \"feature_selection_info.json\")\n",
    "    \n",
    "    attn = np.load(attention_file)\n",
    "\n",
    "    with open(attention_file_info, \"r\") as f:\n",
    "        data_meta = json.load(f)\n",
    "        \n",
    "    return attn, data_meta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7f00e9-d817-4c07-9b8c-ab094b5d52fc",
   "metadata": {},
   "source": [
    "### Attention matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec97516a-86cf-49be-ba12-d9a18bf8c85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ellipse_arc(x_center=0, y_center=0, ax1 = [1, 0],  ax2 = [0,1], a=1, b =1,  N=100):\n",
    "    # x_center, y_center the coordinates of ellipse center\n",
    "    # ax1 ax2 two orthonormal vectors representing the ellipse axis directions\n",
    "    # a, b the ellipse parameters\n",
    "    if not np.isclose(np.linalg.norm(ax1), 1) or not np.isclose(np.linalg.norm(ax2), 1):\n",
    "        raise ValueError(\"ax1, ax2 must be unit vectors\")\n",
    "    if  abs(np.dot(ax1, ax2)) > 1e-06:\n",
    "        raise ValueError(\"ax1, ax2 must be orthogonal vectors\")\n",
    "    t = np.linspace(0, 2*np.pi, N)\n",
    "    #ellipse parameterization with respect to a system of axes of directions a1, a2\n",
    "    xs = a * np.cos(t)\n",
    "    ys = b * np.sin(t)\n",
    "    #rotation matrix\n",
    "    R = np.array([ax1, ax2]).T\n",
    "    # coordinate of the  ellipse points with respect to the system of axes [1, 0], [0,1] with origin (0,0)\n",
    "    xp, yp = np.dot(R, [xs, ys])\n",
    "    x = xp + x_center \n",
    "    y = yp + y_center\n",
    "    return x, y\n",
    "\n",
    "def plot_attn_scatter(attn, labels, figure, cluster_labels=None, reduction_method=decomposition.PCA(n_components=2)):\n",
    "    attn_plottable = reduction_method.fit_transform(attn)\n",
    "    \n",
    "    for l in np.unique(labels).astype(int):\n",
    "        l_mask = (labels == l)\n",
    "        fig.add_trace(go.Scatter(\n",
    "                        name=f\"C{l}\",\n",
    "                        x=attn_plottable[l_mask, 0],\n",
    "                        y=attn_plottable[l_mask, 1],\n",
    "                        mode=\"markers\",\n",
    "                        marker=dict(\n",
    "                            color=COLORS[l],\n",
    "                            size=6\n",
    "                        )\n",
    "        ))\n",
    "\n",
    "    if cluster_labels is not None:\n",
    "        for c_l in np.unique(cluster_labels).astype(int):\n",
    "            c_l_mask = (cluster_labels == c_l)\n",
    "\n",
    "            c_attn = attn_plottable[c_l_mask]\n",
    "            \n",
    "            is_switched = False\n",
    "            \n",
    "            if np.max(c_attn[:, 0]) - np.min(c_attn[:, 0]) > np.max(c_attn[:, 1]) - np.min(c_attn[:, 1]):\n",
    "                xs = c_attn[:, 0]\n",
    "                ys = c_attn[:, 1]\n",
    "            else:\n",
    "                is_switched = True\n",
    "                xs = c_attn[:, 1]\n",
    "                ys = c_attn[:, 0]\n",
    "            \n",
    "            x_center = np.min(xs) + (np.max(xs) - np.min(xs)) / 2\n",
    "            y_center = np.min(ys) + (np.max(ys) - np.min(ys)) / 2\n",
    "\n",
    "            coefs = np.linalg.lstsq(\n",
    "                            xs[:, None], \n",
    "                            ys, rcond=None)[0]\n",
    "\n",
    "            ax1 = np.array([1, 1 * coefs[0]])\n",
    "            ax1 = ax1 / np.linalg.norm(ax1)\n",
    "\n",
    "            ax2 = np.array([1, -ax1[0] / ax1[1]])\n",
    "            ax2 = ax2 / np.linalg.norm(ax2)\n",
    "            \n",
    "            x, y = ellipse_arc(\n",
    "                    x_center=0, \n",
    "                    y_center=0, \n",
    "                    ax1=ax1,\n",
    "                    ax2=ax2,\n",
    "                    a=(np.max(xs) - np.min(xs)) * 0.7, \n",
    "                    b=(np.max(ys) - np.min(ys)) * 0.7\n",
    "                )\n",
    "            \n",
    "            \n",
    "            \n",
    "            fig.add_trace(go.Scatter(\n",
    "                        name=f\"Cluster {c_l}\",\n",
    "                        x=x + x_center if not is_switched else y + y_center,\n",
    "                        y=y + y_center if not is_switched else x + x_center,\n",
    "                        mode=\"lines\",\n",
    "                        line=dict(\n",
    "                            color=COLORS[-c_l],\n",
    "                            width=3,\n",
    "                            dash=\"dot\"\n",
    "                        )\n",
    "                ))\n",
    "        \n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66ef22a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jasmine\n",
      "anneal\n",
      "australian\n",
      "kr-vs-kp\n",
      "sylvine\n",
      "nomao\n",
      "volkert\n",
      "adult\n",
      "ldpa\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "dataset_labels_values = {\n",
    "    \"jasmine\": -9,\n",
    "    \"anneal\": -2,\n",
    "    \"australian\": -0.8,\n",
    "    \"kr-vs-kp\": -2,\n",
    "    \"sylvine\": -1,\n",
    "    \"nomao\": -5,\n",
    "    \"volkert\": -1,\n",
    "    \"adult\": -0.8,\n",
    "    \"ldpa\": -1\n",
    "}\n",
    "\n",
    "axis_template = dict(\n",
    "                    showticklabels = False,\n",
    "                    ticks=\"\",\n",
    "                    zeroline=False,\n",
    "                    showgrid=False\n",
    "                )\n",
    "\n",
    "line_style = dict(\n",
    "                            color='#000',\n",
    "                            width=2\n",
    "                        )\n",
    "\n",
    "layout = go.Layout(\n",
    "    margin={\"l\": 0, \"r\": 0, \"b\": 0, \"t\": 0},    \n",
    "    template=\"plotly_white\",\n",
    "    font={\"size\": 22}\n",
    ")\n",
    "\n",
    "for r in best_archs_test.iloc:\n",
    "    dataset = r[\"dataset\"]\n",
    "    selection_metric = r[\"selection_metric\"]\n",
    "    \n",
    "    print(dataset)\n",
    "    \n",
    "    attn, data_meta = load_attention_with_meta(dataset, selection_metric)\n",
    "    labels, cluster_labels = data_meta[\"labels\"], data_meta[\"cluster_labels\"]\n",
    "    n_instances, n_features = attn.shape\n",
    "    \n",
    "    # Plotting as 2D points colored by cluster\n",
    "    if dataset in [\"jasmine\", \"anneal\"]: # Add ommited datasets in list\n",
    "        fig = go.Figure(layout=layout)\n",
    "        \n",
    "        fig = plot_attn_scatter(attn, cluster_labels, fig, cluster_labels=None)\n",
    "        \n",
    "        fig.update_layout(\n",
    "            xaxis=axis_template,\n",
    "            yaxis=axis_template,\n",
    "            legend=dict(\n",
    "                    orientation=\"h\",\n",
    "                    yanchor=\"bottom\",\n",
    "                    y=1.02,\n",
    "                    xanchor=\"right\",\n",
    "                    x=1\n",
    "                )\n",
    "        )\n",
    "        \n",
    "        fig.write_image(os.path.join(ASSETS_DIR, f\"{dataset}_clusters.png\"), scale=IMG_SCALE)\n",
    "\n",
    "\n",
    "    if dataset in [\"jasmine\", \"anneal\"]: # Add ommited datasets in list\n",
    "        \n",
    "        # Adding blank rows for clusters\n",
    "        sep = np.ones((1, n_features)) * np.nan\n",
    "        sep_width = int(n_instances * 0.01)\n",
    "        sep_indices = np.unique(cluster_labels, return_index=True)[1]\n",
    "        rep_sep_indices = np.repeat(sep_indices[1:], sep_width)\n",
    "        attn = np.insert(attn, rep_sep_indices, sep, axis=0)\n",
    "        brace_labels = np.insert(labels, rep_sep_indices, -1, axis=0)\n",
    "                \n",
    "        # Adding blank rows for labels\n",
    "        l_sep_width = int(n_instances * 0.01)\n",
    "        original_clusters_limits = np.array(sep_indices.tolist() + [n_instances])\n",
    "        l_sep_indices = []\n",
    "        for s_i, (s_i_s, s_i_e) in enumerate(zip(original_clusters_limits[:-1], original_clusters_limits[1:])):\n",
    "            l_sep_indices += (\n",
    "                            np.unique(labels[s_i_s:s_i_e], return_index=True)[1] \\\n",
    "                            + s_i_s \n",
    "                            + s_i * sep_width\n",
    "                        ).tolist()\n",
    "        \n",
    "        l_rep_sep_indices = np.repeat(l_sep_indices[1:], l_sep_width)\n",
    "        attn = np.insert(attn, l_rep_sep_indices, sep, axis=0)\n",
    "        brace_labels = np.insert(brace_labels, l_rep_sep_indices, -1, axis=0)\n",
    "    \n",
    "        \n",
    "        # Adding braces \n",
    "        braces_indices = np.concatenate([sep_indices, [n_instances]])\n",
    "        data = []\n",
    "        annotations = []\n",
    "        for i, (s, f) in enumerate(zip(braces_indices[:-1], braces_indices[1:])):\n",
    "            e_offset = (l_sep_indices < f).sum()\n",
    "            s_offset = (l_sep_indices < s).sum()\n",
    "            \n",
    "            lower_val = s + i * sep_width + s_offset * l_sep_width\n",
    "            upper_val = f + i * sep_width + e_offset * l_sep_width\n",
    "            middle_val = lower_val + (upper_val - lower_val) // 2\n",
    "            \n",
    "            center_val = dataset_labels_values[dataset]\n",
    "            right_val = center_val - 0.3 * dataset_labels_values[dataset]\n",
    "            left_val = center_val + 0.3 * dataset_labels_values[dataset]\n",
    "            \n",
    "            brace = go.Scatter(\n",
    "                            x=[right_val, center_val, center_val, left_val, center_val, center_val, right_val], \n",
    "                            y=[lower_val, lower_val, middle_val, middle_val, middle_val, upper_val, upper_val], \n",
    "                            mode=\"lines\", \n",
    "                            line=line_style\n",
    "                        )\n",
    "            data.append(brace)\n",
    "            \n",
    "            ann_color = \"#000\"\n",
    "            \n",
    "            annotations.append(dict(\n",
    "                                text=f\"C{cluster_labels[s]}\", \n",
    "                                x=left_val * 1.5, \n",
    "                                y=middle_val,\n",
    "                                color=ann_color\n",
    "                                ))\n",
    "        \n",
    "        l_sep_indices = np.array(l_sep_indices + [n_instances + (len(np.unique(cluster_labels)) - 1) * sep_width ])\n",
    "        for i, (s, f) in enumerate(zip(l_sep_indices[:-1], l_sep_indices[1:])):\n",
    "            lower_val = s + i * l_sep_width\n",
    "            upper_val = f + i * l_sep_width\n",
    "            middle_val = lower_val + (upper_val - lower_val) // 2\n",
    "            \n",
    "            center_val = n_features - 1 - dataset_labels_values[dataset]\n",
    "            right_val = center_val - 0.3 * dataset_labels_values[dataset]\n",
    "            left_val = center_val + 0.3 * dataset_labels_values[dataset]\n",
    "            \n",
    "            brace = go.Scatter(\n",
    "                            x=[left_val, center_val, center_val, right_val, center_val, center_val, left_val], \n",
    "                            y=[lower_val, lower_val, middle_val, middle_val, middle_val, upper_val, upper_val], \n",
    "                            mode=\"lines\", \n",
    "                            line=line_style\n",
    "                        )\n",
    "            data.append(brace)\n",
    "            annotations.append(dict(\n",
    "                                text=f\"L{int(brace_labels[lower_val])}\", \n",
    "                                x=right_val - 0.5 * dataset_labels_values[dataset], \n",
    "                                y=middle_val,\n",
    "                                color=\"#000\"\n",
    "                                ))\n",
    "        \n",
    "        \n",
    "           \n",
    "        heatmap_trace = go.Heatmap(x=np.arange(n_features), y=np.arange(n_instances), z=attn, colorscale=\"Inferno\", zsmooth=False)\n",
    "        data = [heatmap_trace] + data\n",
    "        fig = go.Figure(data=data, layout=layout)\n",
    "        \n",
    "        fig.update_layout(\n",
    "            xaxis=axis_template,\n",
    "            yaxis=axis_template,\n",
    "            showlegend=False\n",
    "        )\n",
    "        \n",
    "        fig.update_yaxes(autorange=\"reversed\")\n",
    "        \n",
    "        for a in annotations:\n",
    "            fig.add_annotation(x=a[\"x\"], y=a[\"y\"], text=a[\"text\"], showarrow=False, font=dict(color=a[\"color\"], size=22))\n",
    "            \n",
    "        fig.write_image(os.path.join(ASSETS_DIR, f\"{dataset}_attention.png\"), scale=IMG_SCALE)\n",
    "            \n",
    "    \n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ed2617-ce1f-48db-843e-1b74a3f2cdc7",
   "metadata": {},
   "source": [
    "### Attention graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "59b0b3a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "dataset = \"anneal\"\n",
    "instance_index = 604\n",
    "\n",
    "attn, data_meta = load_attention_with_meta(dataset, OPTIMIZATION_METRIC)\n",
    "labels, cluster_labels = data_meta[\"labels\"], data_meta[\"cluster_labels\"]\n",
    "\n",
    "sep = np.ones((1, attn.shape[1])) * np.nan\n",
    "sep_width = int(attn.shape[0] * 0.01)\n",
    "rep_sep_indices = np.repeat([instance_index, instance_index + 1], sep_width)\n",
    "rep_inst_index = np.repeat([instance_index + sep_width], 3 * sep_width)\n",
    "attn = np.insert(attn, rep_sep_indices, sep, axis=0)\n",
    "attn = np.insert(attn, rep_inst_index, attn[instance_index + sep_width][None, :], axis=0)\n",
    "\n",
    "data = []\n",
    "heatmap_trace = go.Heatmap(z=attn, zmin=np.nanmin(attn), zmax=np.nanmax(attn), colorscale=\"Inferno\")\n",
    "data += [heatmap_trace] \n",
    "\n",
    "fig = go.Figure(data=data, layout=go.Layout(\n",
    "                            margin={\"l\": 35, \"r\": 0, \"b\": 0, \"t\": 0},    \n",
    "                            template=\"plotly_white\",\n",
    "                            font={\"size\": 20}\n",
    "                        ))\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis=dict(\n",
    "        tickmode = \"array\",\n",
    "        tickvals = np.arange(0, attn.shape[-1], 5),\n",
    "        ticktext = [str(i) for i in np.arange(0, attn.shape[-1], 5) + 1],\n",
    "        zeroline=False, \n",
    "        showgrid=False\n",
    "    ),\n",
    "    yaxis=dict(showticklabels=False, ticks=\"\", zeroline=False, showgrid=False),\n",
    "    xaxis_title=\"Features\",\n",
    "    yaxis_title=\"Instances\",\n",
    "    showlegend=False\n",
    ")\n",
    "\n",
    "fig.update_yaxes(autorange=\"reversed\")\n",
    "fig.write_image(os.path.join(ASSETS_DIR, f\"{dataset}_attention_graph_instance.png\"), scale=IMG_SCALE)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "670bc1c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:++++++++++++++++++++++++++++++++++++++++ Extracting anneal-log_loss\n",
      "INFO:root:Loading preprocessor\n",
      "INFO:root:Reading data\n",
      "INFO:root:Training size: (718, 33)\n",
      "INFO:root:Test size: (180, 33)\n",
      "INFO:root:Total size: (898, 33)\n",
      "INFO:root:Sorting dataset as original\n",
      "INFO:root:Preprocessing data\n",
      "INFO:root:Building model\n",
      "INFO:root:Loading checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uriel/Miniconda3/envs/TT/lib/python3.11/site-packages/torch/nn/modules/transformer.py:286: UserWarning:\n",
      "\n",
      "enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer was not TransformerEncoderLayer\n",
      "\n"
     ]
    }
   ],
   "source": [
    "d_job = best_archs_test.query(\"dataset==@dataset\").to_dict()\n",
    "d_job = {k: list(v.values())[0] for k, v in d_job.items()}\n",
    "d_job[\"aggregator\"] = list(MAPPINGS[\"aggregator_name\"].keys())[list(MAPPINGS[\"aggregator_name\"].values()).index(d_job[\"aggregator\"])]\n",
    "\n",
    "result = attention.extract_attention(\n",
    "        dataset,\n",
    "        d_job[\"checkpoint_dir\"],\n",
    "        d_job[\"aggregator\"],\n",
    "        OPTIMIZATION_METRIC,\n",
    "        d_job, \n",
    "        only_last=False,\n",
    "        return_cubes=True\n",
    "    )\n",
    "\n",
    "layers_attn = result[\"cumulated_attention\"][:, data_meta[\"data_required_sort\"]]\n",
    "cubes_attn = result[\"attention_cubes\"][:, data_meta[\"data_required_sort\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "16995285",
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_attn = layers_attn[:, instance_index]\n",
    "instance_cube = cubes_attn[:, instance_index]\n",
    "assert np.allclose(instance_attn[-1], attn[instance_index + sep_width]), \"Error selecting instance\"\n",
    "\n",
    "instance_cube[instance_cube < 0.3] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b3a9c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "fig = go.Figure(layout=go.Layout(\n",
    "                            margin={\"l\": 50, \"r\": 0, \"b\": 0, \"t\": 0},\n",
    "                            template=\"plotly_white\",\n",
    "                            font={\"size\": 20}\n",
    "                        ))\n",
    "\n",
    "n_layers, n_heads, n_features, _ = instance_cube.shape\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x = np.repeat(np.arange(n_features)[None], n_layers + 1, 0).flatten(),\n",
    "    y = np.repeat(np.arange(n_layers + 1), n_features, 0),\n",
    "    mode=\"markers\",\n",
    "    marker=dict(\n",
    "        color = np.concatenate([np.zeros(n_features), instance_attn.flatten()]),\n",
    "        colorscale=\"Inferno\",\n",
    "        cmax=np.nanmax(attn),\n",
    "        cmin=np.nanmin(attn),\n",
    "        size=15,\n",
    "        symbol=\"square\",\n",
    "        showscale=False\n",
    "    )\n",
    "    \n",
    "))\n",
    "\n",
    "\n",
    "for l in range(n_layers):\n",
    "    for h in range(n_heads):\n",
    "        for o in range(n_features):\n",
    "            for i in range(n_features):\n",
    "                if not np.isnan(instance_cube[l, h, o, i]):\n",
    "                    fig.add_shape(\n",
    "                        type=\"line\",\n",
    "                        x0=i, y0=l + 0.08, \n",
    "                        x1=o, y1=l + 1 - 0.08,\n",
    "                        line=dict(\n",
    "                            color=COLORS[h],\n",
    "                            width=instance_cube[l, h, o, i],\n",
    "                        )\n",
    "                    )\n",
    "                    \n",
    "fig.update_layout(\n",
    "    xaxis=dict(\n",
    "        tickmode = \"array\",\n",
    "        tickvals = np.arange(0, attn.shape[-1], 5),\n",
    "        ticktext = [str(i) for i in np.arange(0, attn.shape[-1], 5) + 1],\n",
    "        zeroline=False, \n",
    "        showgrid=False\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        tickmode = \"array\",\n",
    "        tickvals = np.arange(n_layers + 1),\n",
    "        ticktext = [str(i) if i > 0 else \"In\" for i in np.arange(n_layers + 1)],\n",
    "        zeroline=False, \n",
    "        showgrid=False\n",
    "    ),\n",
    "    xaxis_title=\"Features\",\n",
    "    yaxis_title=\"Layers\",\n",
    "    showlegend=False,\n",
    ")\n",
    "\n",
    "fig.write_image(os.path.join(ASSETS_DIR, f\"{dataset}_attention_graph.png\"), scale=IMG_SCALE)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fedfd8",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737b9e89",
   "metadata": {},
   "source": [
    "### Cases of study - Clustering mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "61e07ff5-a473-4966-a3b5-fe74684b3a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_mapping = {\n",
    "    \"selection_method\": {\n",
    "        \"attention\": \"Attention\",\n",
    "        \"linear_model\": \"Linear model\",\n",
    "        \"decision_tree\": \"Decision tree\",\n",
    "        \"f_classif\": \"F-score\",\n",
    "        \"random\": \"Random\"\n",
    "    },\n",
    "    \"model\": {\n",
    "        \"KNN\": \"kNN\",\n",
    "        \"MLP\": \"MLP\"\n",
    "    },\n",
    "}\n",
    "\n",
    "no_selection_str = \"No selection\"\n",
    "\n",
    "def rank_sort(x):\n",
    "    if x in DATASET_ORDER:\n",
    "        return DATASET_ORDER.index(x)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b3f1c15d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>jasmine</td>\n",
       "      <td>C0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>jasmine</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>jasmine</td>\n",
       "      <td>C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>jasmine</td>\n",
       "      <td>C3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>anneal</td>\n",
       "      <td>C0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>anneal</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>anneal</td>\n",
       "      <td>C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>anneal</td>\n",
       "      <td>C3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>australian</td>\n",
       "      <td>C0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>australian</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>australian</td>\n",
       "      <td>C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>australian</td>\n",
       "      <td>C3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>kr-vs-kp</td>\n",
       "      <td>C0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>sylvine</td>\n",
       "      <td>C0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>sylvine</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>sylvine</td>\n",
       "      <td>C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>sylvine</td>\n",
       "      <td>C3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>nomao</td>\n",
       "      <td>C0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>nomao</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>nomao</td>\n",
       "      <td>C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>nomao</td>\n",
       "      <td>C3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>volkert</td>\n",
       "      <td>C0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>volkert</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>volkert</td>\n",
       "      <td>C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>volkert</td>\n",
       "      <td>C3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adult</td>\n",
       "      <td>C0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>adult</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>adult</td>\n",
       "      <td>C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>adult</td>\n",
       "      <td>C3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>ldpa</td>\n",
       "      <td>C0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>ldpa</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>ldpa</td>\n",
       "      <td>C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>ldpa</td>\n",
       "      <td>C3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        dataset cluster\n",
       "216     jasmine      C0\n",
       "234     jasmine      C1\n",
       "252     jasmine      C2\n",
       "270     jasmine      C3\n",
       "72       anneal      C0\n",
       "90       anneal      C1\n",
       "108      anneal      C2\n",
       "126      anneal      C3\n",
       "144  australian      C0\n",
       "162  australian      C1\n",
       "180  australian      C2\n",
       "198  australian      C3\n",
       "288    kr-vs-kp      C0\n",
       "450     sylvine      C0\n",
       "468     sylvine      C1\n",
       "486     sylvine      C2\n",
       "504     sylvine      C3\n",
       "378       nomao      C0\n",
       "396       nomao      C1\n",
       "414       nomao      C2\n",
       "432       nomao      C3\n",
       "522     volkert      C0\n",
       "540     volkert      C1\n",
       "558     volkert      C2\n",
       "576     volkert      C3\n",
       "0         adult      C0\n",
       "18        adult      C1\n",
       "36        adult      C2\n",
       "54        adult      C3\n",
       "306        ldpa      C0\n",
       "324        ldpa      C1\n",
       "342        ldpa      C2\n",
       "360        ldpa      C3"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs_scores_df = pd.read_csv(\"feature_selection_cluster_fmask_scores.csv\")\n",
    "fs_scores_df = fs_scores_df.sort_values([\"dataset\", \"selection_method\"], key=lambda x: x.apply(rank_sort))\n",
    "fs_scores_df[[\"dataset\", \"cluster\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e410e602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unify random scores\n",
    "random_scores = fs_scores_df.query(\"selection_method.str.contains('random')\")\n",
    "\n",
    "random_scores = random_scores.drop([\"selection_method\"], axis=1)\n",
    "random_scores = random_scores.groupby(\n",
    "                    [\"dataset\", \"cluster\", \"model\", \"opt_metric\", \"features_percent\", \"n_features_selected\"], \n",
    "                    as_index=False).agg([\"mean\", \"std\"])\n",
    "\n",
    "random_scores.columns = [\"_\".join(col) if col[1] else col[0] for col in random_scores.columns] \n",
    "random_scores = random_scores[[\n",
    "                    \"dataset\", \"cluster\", \"model\", \"opt_metric\", \"features_percent\", \"n_features_selected\", \n",
    "                    \"balanced_accuracy_mean_mean\", \"balanced_accuracy_mean_std\",\n",
    "                    \"accuracy_mean_mean\", \"accuracy_mean_std\"\n",
    "                ]]\n",
    "\n",
    "random_scores.columns = [\n",
    "                    \"dataset\", \"cluster\", \"model\", \"opt_metric\", \"features_percent\", \"n_features_selected\",\n",
    "                    \"balanced_accuracy_mean\", \"balanced_accuracy_std\",\n",
    "                    \"accuracy_mean\", \"accuracy_std\"\n",
    "                ]\n",
    "random_scores[\"selection_method\"] = \"random\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0c340ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set to original dataset\n",
    "fs_scores_df = pd.concat([\n",
    "        fs_scores_df.query(\"not selection_method.str.contains('random')\"),\n",
    "        random_scores\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242ed58d",
   "metadata": {},
   "source": [
    "#### Executions per dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "43f954ea-00cf-4f82-ab2c-783f33bd9694",
   "metadata": {},
   "outputs": [],
   "source": [
    "layout = go.Layout(\n",
    "    margin={\"l\": 80, \"r\": 0, \"b\": 0, \"t\": 0},    \n",
    "    template=\"plotly_white\",\n",
    "    font={\"size\": 22}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4280e872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "cos_model = \"KNN\"\n",
    "cos_feat_percent = 0.1\n",
    "cos_cluster = \"C0\"\n",
    "\n",
    "for cos_model in [\"KNN\", \"MLP\"]:\n",
    "    for cos_feat_percent in [0.1]:\n",
    "        for cos_cluster in [\"C0\", \"C1\", \"C2\", \"C3\"]:\n",
    "            cos_df = fs_scores_df.query(\n",
    "                \"opt_metric==@OPTIMIZATION_METRIC \"\n",
    "                \"and model==@cos_model \"\n",
    "                \"and features_percent==@cos_feat_percent \"\n",
    "                \"and cluster==@cos_cluster \"\n",
    "            )\n",
    "\n",
    "            cos_df = cos_df[[\n",
    "                    \"dataset\",\n",
    "                    \"cluster\",\n",
    "                    \"selection_method\",\n",
    "                    \"features_percent\",        \n",
    "                    f\"{EVALUATION_METRIC}_mean\", \n",
    "                    f\"{EVALUATION_METRIC}_std\", \n",
    "            ]].replace(columns_mapping)\n",
    "\n",
    "\n",
    "            fig = go.Figure(layout=layout)\n",
    "\n",
    "\n",
    "            for sel_method_i, sel_method in enumerate(cos_df[\"selection_method\"].unique()):\n",
    "                plot_data = cos_df.query(\"selection_method==@sel_method\")\n",
    "                \n",
    "                fig.add_trace(go.Bar(\n",
    "                    name=sel_method, \n",
    "                    x=plot_data[\"dataset\"], \n",
    "                    y=plot_data[f\"{EVALUATION_METRIC}_mean\"],\n",
    "                    error_y=dict(\n",
    "                                type=\"data\", \n",
    "                                array=plot_data[f\"{EVALUATION_METRIC}_std\"],\n",
    "                                color=\"rgba(0, 0, 0, 0.7)\"\n",
    "                                ),\n",
    "                    marker_color=COLORS[sel_method_i]\n",
    "                ))\n",
    "\n",
    "\n",
    "            # Adding lines of non feature selection scores    \n",
    "            cos_df = fs_scores_df.query(\n",
    "                \"opt_metric==@OPTIMIZATION_METRIC \"\n",
    "                \"and model==@cos_model \"\n",
    "                \"and features_percent==1 \"\n",
    "                \"and cluster==@cos_cluster \"\n",
    "            )\n",
    "            plot_data = cos_df.drop([\"selection_method\"], axis=1).drop_duplicates()\n",
    "\n",
    "            for ds_i, ds in enumerate(cos_df[\"dataset\"].unique()):\n",
    "                nfs_metric = plot_data.query(\"dataset==@ds\")[f\"{EVALUATION_METRIC}_mean\"].values[0]\n",
    "                fig.add_shape(type=\"line\",\n",
    "                                x0=ds_i - 0.45,\n",
    "                                y0=nfs_metric,\n",
    "                                x1=ds_i + 0.45,\n",
    "                                y1=nfs_metric,\n",
    "                                line=dict(color=COLORS[-1], width=2.5, dash=\"dot\"),\n",
    "                                xref=\"x\",\n",
    "                                yref=\"y\",\n",
    "                                name=no_selection_str,\n",
    "                                showlegend=True if ds_i == 0 else False\n",
    "                )\n",
    "            \n",
    "            fig.update_layout(\n",
    "                yaxis_title = \"Balanced accuracy\",\n",
    "                legend=dict(\n",
    "                    orientation=\"h\",\n",
    "                    yanchor=\"bottom\",\n",
    "                    y=1.02,\n",
    "                    xanchor=\"right\",\n",
    "                    x=1\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            fig.write_image(os.path.join(ASSETS_DIR, f\"results_cluster_{cos_model}_{cos_feat_percent}_{cos_cluster}.png\"), scale=IMG_SCALE)\n",
    "            \n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "38dfd155",
   "metadata": {},
   "outputs": [],
   "source": [
    "layout = go.Layout(\n",
    "    margin={\"l\": 80, \"r\": 0, \"b\": 0, \"t\": 0},    \n",
    "    template=\"plotly_white\",\n",
    "    font={\"size\": 22}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "14fd2ac3-c1ea-478c-8e7c-e1e513e0eaac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "cos_dataset = \"jasmine\"\n",
    "cos_feat_percent = 0.1\n",
    "cos_cluster = \"C3\"\n",
    "\n",
    "\n",
    "\n",
    "for cos_dataset in [\"anneal\", \"jasmine\"]:\n",
    "    for cos_feat_percent in [0.1]:\n",
    "        for cos_cluster in [\"C0\", \"C1\", \"C2\", \"C3\"]:\n",
    "            \n",
    "            cos_df = fs_scores_df.query(\n",
    "                \"opt_metric==@OPTIMIZATION_METRIC \"\n",
    "                \"and dataset==@cos_dataset \"\n",
    "                \"and features_percent==@cos_feat_percent \"\n",
    "                \"and cluster==@cos_cluster \"\n",
    "            )\n",
    "\n",
    "            cos_df = cos_df[[\n",
    "                    \"dataset\",\n",
    "                    \"model\",\n",
    "                    \"cluster\",\n",
    "                    \"selection_method\",\n",
    "                    \"features_percent\",        \n",
    "                    f\"{EVALUATION_METRIC}_mean\", \n",
    "                    f\"{EVALUATION_METRIC}_std\", \n",
    "            ]].replace(columns_mapping)\n",
    "\n",
    "\n",
    "            fig = go.Figure(layout=layout)\n",
    "\n",
    "            for sel_method_i, sel_method in enumerate(cos_df[\"selection_method\"].unique()):\n",
    "                plot_data = cos_df.query(\"selection_method==@sel_method\")\n",
    "                fig.add_trace(go.Bar(\n",
    "                    name=sel_method, \n",
    "                    x=plot_data[\"model\"], \n",
    "                    y=plot_data[f\"{EVALUATION_METRIC}_mean\"],\n",
    "                    error_y=dict(\n",
    "                                type=\"data\", \n",
    "                                array=plot_data[f\"{EVALUATION_METRIC}_std\"],\n",
    "                                color=\"rgba(0, 0, 0, 0.7)\"\n",
    "                                ),\n",
    "                    marker_color=COLORS[sel_method_i]\n",
    "                ))\n",
    "\n",
    "\n",
    "            # Adding lines of non feature selection scores    \n",
    "            cos_df = fs_scores_df.query(\n",
    "                \"opt_metric==@OPTIMIZATION_METRIC \"\n",
    "                \"and dataset==@cos_dataset \"\n",
    "                \"and features_percent==1 \"\n",
    "                \"and cluster==@cos_cluster \"\n",
    "            )\n",
    "            plot_data = cos_df.drop([\"selection_method\"], axis=1).drop_duplicates()\n",
    "\n",
    "            for mod_i, mod in enumerate(cos_df[\"model\"].unique()):\n",
    "                nfs_metric = plot_data.query(\"model==@mod\")[f\"{EVALUATION_METRIC}_mean\"].values[0]\n",
    "                fig.add_shape(type=\"line\",\n",
    "                                x0=mod_i - 0.45,\n",
    "                                y0=nfs_metric,\n",
    "                                x1=mod_i + 0.45,\n",
    "                                y1=nfs_metric,\n",
    "                                line=dict(color=COLORS[-1], width=2.5, dash=\"dot\"),\n",
    "                                xref=\"x\",\n",
    "                                yref=\"y\",\n",
    "                                name=no_selection_str,\n",
    "                                showlegend=True if mod_i == 0 else False\n",
    "                )\n",
    "\n",
    "            fig.update_layout(\n",
    "                yaxis_title = \"Balanced accuracy\",\n",
    "                legend=dict(\n",
    "                    orientation=\"h\",\n",
    "                    yanchor=\"bottom\",\n",
    "                    y=1.02,\n",
    "                    xanchor=\"right\",\n",
    "                    x=1\n",
    "                )\n",
    "            )\n",
    "\n",
    "            fig.write_image(os.path.join(ASSETS_DIR, f\"results_cluster_{cos_dataset}_{cos_feat_percent}_{cos_cluster}.png\"), scale=IMG_SCALE)\n",
    "            \n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0529ac",
   "metadata": {},
   "source": [
    "### Cases of study - Full dataset mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ba22a2a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>cluster</th>\n",
       "      <th>model</th>\n",
       "      <th>selection_method</th>\n",
       "      <th>opt_metric</th>\n",
       "      <th>n_features_selected</th>\n",
       "      <th>features_percent</th>\n",
       "      <th>balanced_accuracy_mean</th>\n",
       "      <th>balanced_accuracy_std</th>\n",
       "      <th>accuracy_mean</th>\n",
       "      <th>accuracy_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>jasmine</td>\n",
       "      <td>C0</td>\n",
       "      <td>KNN</td>\n",
       "      <td>attention</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>14</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.522792</td>\n",
       "      <td>0.012625</td>\n",
       "      <td>0.522794</td>\n",
       "      <td>0.012494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>jasmine</td>\n",
       "      <td>C0</td>\n",
       "      <td>KNN</td>\n",
       "      <td>decision_tree</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>14</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.786168</td>\n",
       "      <td>0.028348</td>\n",
       "      <td>0.786170</td>\n",
       "      <td>0.028330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>jasmine</td>\n",
       "      <td>C0</td>\n",
       "      <td>KNN</td>\n",
       "      <td>f_classif</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>14</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.637333</td>\n",
       "      <td>0.069500</td>\n",
       "      <td>0.637322</td>\n",
       "      <td>0.069487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>jasmine</td>\n",
       "      <td>C0</td>\n",
       "      <td>KNN</td>\n",
       "      <td>linear_model</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>14</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.752092</td>\n",
       "      <td>0.043707</td>\n",
       "      <td>0.752016</td>\n",
       "      <td>0.043743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>jasmine</td>\n",
       "      <td>C0</td>\n",
       "      <td>KNN</td>\n",
       "      <td>random</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>14</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.623376</td>\n",
       "      <td>0.065357</td>\n",
       "      <td>0.623346</td>\n",
       "      <td>0.065515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>ldpa</td>\n",
       "      <td>C0</td>\n",
       "      <td>MLP</td>\n",
       "      <td>random_2</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.402745</td>\n",
       "      <td>0.006350</td>\n",
       "      <td>0.690198</td>\n",
       "      <td>0.003239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>ldpa</td>\n",
       "      <td>C0</td>\n",
       "      <td>KNN</td>\n",
       "      <td>random_3</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.517797</td>\n",
       "      <td>0.004779</td>\n",
       "      <td>0.760815</td>\n",
       "      <td>0.002297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>ldpa</td>\n",
       "      <td>C0</td>\n",
       "      <td>MLP</td>\n",
       "      <td>random_3</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.402745</td>\n",
       "      <td>0.006350</td>\n",
       "      <td>0.690198</td>\n",
       "      <td>0.003239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>ldpa</td>\n",
       "      <td>C0</td>\n",
       "      <td>KNN</td>\n",
       "      <td>random_4</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.517797</td>\n",
       "      <td>0.004779</td>\n",
       "      <td>0.760815</td>\n",
       "      <td>0.002297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>ldpa</td>\n",
       "      <td>C0</td>\n",
       "      <td>MLP</td>\n",
       "      <td>random_4</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.402745</td>\n",
       "      <td>0.006350</td>\n",
       "      <td>0.690198</td>\n",
       "      <td>0.003239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>324 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     dataset cluster model selection_method opt_metric  n_features_selected  \\\n",
       "54   jasmine      C0   KNN        attention   log_loss                   14   \n",
       "55   jasmine      C0   KNN    decision_tree   log_loss                   14   \n",
       "56   jasmine      C0   KNN        f_classif   log_loss                   14   \n",
       "57   jasmine      C0   KNN     linear_model   log_loss                   14   \n",
       "58   jasmine      C0   KNN           random   log_loss                   14   \n",
       "..       ...     ...   ...              ...        ...                  ...   \n",
       "281     ldpa      C0   MLP         random_2   log_loss                    7   \n",
       "298     ldpa      C0   KNN         random_3   log_loss                    7   \n",
       "299     ldpa      C0   MLP         random_3   log_loss                    7   \n",
       "316     ldpa      C0   KNN         random_4   log_loss                    7   \n",
       "317     ldpa      C0   MLP         random_4   log_loss                    7   \n",
       "\n",
       "     features_percent  balanced_accuracy_mean  balanced_accuracy_std  \\\n",
       "54                0.1                0.522792               0.012625   \n",
       "55                0.1                0.786168               0.028348   \n",
       "56                0.1                0.637333               0.069500   \n",
       "57                0.1                0.752092               0.043707   \n",
       "58                0.1                0.623376               0.065357   \n",
       "..                ...                     ...                    ...   \n",
       "281               1.0                0.402745               0.006350   \n",
       "298               1.0                0.517797               0.004779   \n",
       "299               1.0                0.402745               0.006350   \n",
       "316               1.0                0.517797               0.004779   \n",
       "317               1.0                0.402745               0.006350   \n",
       "\n",
       "     accuracy_mean  accuracy_std  \n",
       "54        0.522794      0.012494  \n",
       "55        0.786170      0.028330  \n",
       "56        0.637322      0.069487  \n",
       "57        0.752016      0.043743  \n",
       "58        0.623346      0.065515  \n",
       "..             ...           ...  \n",
       "281       0.690198      0.003239  \n",
       "298       0.760815      0.002297  \n",
       "299       0.690198      0.003239  \n",
       "316       0.760815      0.002297  \n",
       "317       0.690198      0.003239  \n",
       "\n",
       "[324 rows x 11 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs_ds_scores_df = pd.read_csv(\"feature_selection_dataset_fmask_scores.csv\")\n",
    "fs_ds_scores_df = fs_ds_scores_df.sort_values([\"dataset\", \"selection_method\"], key=lambda x: x.apply(rank_sort))\n",
    "fs_ds_scores_df[[\"dataset\", \"cluster\"]].drop_duplicates()\n",
    "fs_ds_scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7dce2888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unify random scores\n",
    "random_scores = fs_ds_scores_df.query(\"selection_method.str.contains('random')\")\n",
    "\n",
    "random_scores = random_scores.drop([\"selection_method\"], axis=1)\n",
    "random_scores = random_scores.groupby(\n",
    "                    [\"dataset\", \"cluster\", \"model\", \"opt_metric\", \"features_percent\", \"n_features_selected\"], \n",
    "                    as_index=False).agg([\"mean\", \"std\"])\n",
    "\n",
    "random_scores.columns = [\"_\".join(col) if col[1] else col[0] for col in random_scores.columns] \n",
    "random_scores = random_scores[[\n",
    "                    \"dataset\", \"cluster\", \"model\", \"opt_metric\", \"features_percent\", \"n_features_selected\", \n",
    "                    \"balanced_accuracy_mean_mean\", \"balanced_accuracy_mean_std\",\n",
    "                    \"accuracy_mean_mean\", \"accuracy_mean_std\"\n",
    "                ]]\n",
    "\n",
    "random_scores.columns = [\n",
    "                    \"dataset\", \"cluster\", \"model\", \"opt_metric\", \"features_percent\", \"n_features_selected\",\n",
    "                    \"balanced_accuracy_mean\", \"balanced_accuracy_std\",\n",
    "                    \"accuracy_mean\", \"accuracy_std\"\n",
    "                ]\n",
    "random_scores[\"selection_method\"] = \"random\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eda51aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set to original dataset\n",
    "fs_ds_scores_df = pd.concat([\n",
    "        fs_ds_scores_df.query(\"not selection_method.str.contains('random')\"),\n",
    "        random_scores\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05af5b9e",
   "metadata": {},
   "source": [
    "#### Executions per dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f366825e",
   "metadata": {},
   "outputs": [],
   "source": [
    "layout = go.Layout(\n",
    "    margin={\"l\": 50, \"r\": 0, \"b\": 0, \"t\": 0},    \n",
    "    template=\"plotly_white\",\n",
    "    font={\"size\": 12}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c216c1da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "cos_model = \"KNN\"\n",
    "cos_feat_percent = 0.1\n",
    "\n",
    "for cos_model in [\"KNN\", \"MLP\"]:\n",
    "    for cos_feat_percent in [0.1]:\n",
    "\n",
    "        cos_df = fs_ds_scores_df.query(\n",
    "            \"opt_metric==@OPTIMIZATION_METRIC \"\n",
    "            \"and model==@cos_model \"\n",
    "            \"and features_percent==@cos_feat_percent \"\n",
    "        )\n",
    "\n",
    "        cos_df = cos_df[[\n",
    "                \"dataset\",\n",
    "                \"cluster\",\n",
    "                \"selection_method\",\n",
    "                \"features_percent\",        \n",
    "                f\"{EVALUATION_METRIC}_mean\", \n",
    "                f\"{EVALUATION_METRIC}_std\", \n",
    "        ]].replace(columns_mapping)\n",
    "\n",
    "        fig = go.Figure(layout=layout)\n",
    "\n",
    "        for sel_method_i, sel_method in enumerate(cos_df[\"selection_method\"].unique()):\n",
    "            plot_data = cos_df.query(\"selection_method==@sel_method\")\n",
    "            fig.add_trace(go.Bar(\n",
    "                name=sel_method, \n",
    "                x=plot_data[\"dataset\"], \n",
    "                y=plot_data[f\"{EVALUATION_METRIC}_mean\"],\n",
    "                error_y=dict(\n",
    "                            type=\"data\", \n",
    "                            array=plot_data[f\"{EVALUATION_METRIC}_std\"],\n",
    "                            color=\"rgba(0, 0, 0, 0.7)\"\n",
    "                            ),\n",
    "                marker_color=COLORS[sel_method_i]\n",
    "            ))\n",
    "\n",
    "\n",
    "        # Adding lines of non feature selection scores    \n",
    "        cos_df = fs_ds_scores_df.query(\n",
    "            \"opt_metric==@OPTIMIZATION_METRIC \"\n",
    "            \"and model==@cos_model \"\n",
    "            \"and features_percent==1 \"\n",
    "        )\n",
    "\n",
    "        plot_data = cos_df.drop([\"selection_method\"], axis=1).drop_duplicates()\n",
    "\n",
    "        for ds_i, ds in enumerate(cos_df[\"dataset\"].unique()):\n",
    "            nfs_metric = plot_data.query(\"dataset==@ds\")[f\"{EVALUATION_METRIC}_mean\"].values[0]\n",
    "            fig.add_shape(type=\"line\",\n",
    "                            x0=ds_i - 0.45,\n",
    "                            y0=nfs_metric,\n",
    "                            x1=ds_i + 0.45,\n",
    "                            y1=nfs_metric,\n",
    "                            line=dict(color=COLORS[-1], width=2.5, dash=\"dot\"),\n",
    "                            xref=\"x\",\n",
    "                            yref=\"y\",\n",
    "                            name=no_selection_str,\n",
    "                            showlegend=True if ds_i == 0 else False\n",
    "            )\n",
    "\n",
    "        fig.update_layout(\n",
    "            yaxis_title = \"Balanced accuracy\",\n",
    "            legend=dict(\n",
    "                orientation=\"h\",\n",
    "                yanchor=\"bottom\",\n",
    "                y=1.02,\n",
    "                xanchor=\"right\",\n",
    "                x=1\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        fig.write_image(os.path.join(ASSETS_DIR, f\"results_dataset_{cos_model}_{cos_feat_percent}.png\"), scale=IMG_SCALE)\n",
    "        \n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa0817f-2182-4553-bd5c-9c0d85a7653b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d011850-7058-4c40-a704-e2aa5f187a12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b33afb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
