{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "\n",
    "import skorch\n",
    "from skorch import dataset\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from tab_transformer_pytorch import TabTransformer\n",
    "\n",
    "from sklearn import base, pipeline, preprocessing, compose, metrics, model_selection\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n",
    "numerical_cols = ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "label_col = \"class\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"adult/data/dataset.csv\")\n",
    "data[label_col] = data[label_col].replace({\"<=50K\": 0, \">50K\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age               0\n",
       "workclass         0\n",
       "fnlwgt            0\n",
       "education         0\n",
       "education-num     0\n",
       "marital-status    0\n",
       "occupation        0\n",
       "relationship      0\n",
       "race              0\n",
       "sex               0\n",
       "capital-gain      0\n",
       "capital-loss      0\n",
       "hours-per-week    0\n",
       "native-country    0\n",
       "class             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size=0.65\n",
    "val_size=0.15\n",
    "test_size=0.20\n",
    "seed=11\n",
    "\n",
    "\n",
    "train_features, test_features, train_labels, test_labels = model_selection.train_test_split(\n",
    "    data[categorical_cols + numerical_cols], \n",
    "    data[label_col], \n",
    "    test_size=test_size,\n",
    "    random_state=seed\n",
    ")\n",
    "\n",
    "val_size = data.shape[0] * val_size / train_features.shape[0]\n",
    "\n",
    "train_features, val_features, train_labels, val_labels = model_selection.train_test_split(\n",
    "    train_features, \n",
    "    train_labels, \n",
    "    test_size=val_size, \n",
    "    random_state=seed\n",
    ")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bins = 10\n",
    "n_quantiles = 10\n",
    "\n",
    "categorical_transformer = pipeline.Pipeline(steps=[\n",
    "    ('label', preprocessing.OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)),\n",
    "    ('shift', preprocessing.FunctionTransformer(lambda x: x + 1))\n",
    "])\n",
    "\n",
    "numerical_transformer = pipeline.FeatureUnion([\n",
    "#    ('qtscaler', preprocessing.QuantileTransformer(n_quantiles=n_quantiles)),\n",
    "    ('sscaler', preprocessing.StandardScaler()),\n",
    "#    ('logscaler', preprocessing.FunctionTransformer(np.log1p)),\n",
    "])\n",
    "\n",
    "numerical_categorical_transformer = pipeline.Pipeline(steps=[\n",
    "    ('dscaler', preprocessing.KBinsDiscretizer(n_bins=n_bins, encode=\"ordinal\", strategy=\"uniform\")), \n",
    "])\n",
    "\n",
    "\n",
    "preprocessor = pipeline.Pipeline([\n",
    "    ('columns_transformer', compose.ColumnTransformer(\n",
    "        remainder='passthrough', #passthough features not listed\n",
    "        transformers=[\n",
    "            ('categorical_transformer', categorical_transformer , categorical_cols),\n",
    "            #('numerical_categorical_transformer', numerical_categorical_transformer , numerical_cols),\n",
    "            ('numerical_transformer', numerical_transformer , numerical_cols)\n",
    "        ]),\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training examples 21163 (0.6499493258806548)\n",
      "Validation examples 4885 (0.15002610484935966)\n",
      "Test examples 6513 (0.20002456926998557)\n"
     ]
    }
   ],
   "source": [
    "total_examples = train_features.shape[0] + val_features.shape[0] + test_features.shape[0]\n",
    "\n",
    "print(\"Training examples {} ({})\".format(train_features.shape[0], train_features.shape[0] / total_examples))\n",
    "print(\"Validation examples {} ({})\".format(val_features.shape[0], val_features.shape[0] / total_examples))\n",
    "print(\"Test examples {} ({})\".format(test_features.shape[0], test_features.shape[0] / total_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = preprocessor.fit(train_features, train_labels)\n",
    "\n",
    "train_features = preprocessor.transform(train_features)\n",
    "val_features = preprocessor.transform(val_features)\n",
    "test_features = preprocessor.transform(test_features)\n",
    "\n",
    "all_features = np.concatenate([train_features, val_features])\n",
    "all_labels = np.concatenate([train_labels, val_labels])\n",
    "\n",
    "n_labels = 1\n",
    "criterion = torch.nn.BCEWithLogitsLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(*args, **kwargs):\n",
    "    \n",
    "    module = TabTransformer(\n",
    "        #categories = (8, 16, 7, 14, 6, 5, 2, 41, n_bins, n_bins, n_bins, n_bins, n_bins, n_bins),      # tuple containing the number of unique values within each category\n",
    "        categories = (10, 18, 9, 16, 8, 7, 4, 43),      # tuple containing the number of unique values within each category\n",
    "        #num_continuous = 6 * 3,                # number of continuous values\n",
    "        num_continuous = 6,                # number of continuous values\n",
    "        dim = 32,    \n",
    "        dim_head=32,                       # dimension, paper set at 32\n",
    "        dim_out = 1,                        # binary prediction, but could be anything\n",
    "        depth = 6,                          # depth, paper recommended 6\n",
    "        heads = 8,                          # heads, paper recommends 8\n",
    "        attn_dropout = 0.1,                 # post-attention dropout\n",
    "        ff_dropout = 0.1,                   # feed forward dropout\n",
    "        mlp_hidden_mults = (4, 2),          # relative multiples of each hidden dimension of the last mlp to logits\n",
    "        mlp_act = nn.ReLU(),          # activation for final mlp, defaults to relu, but could be anything else (selu etc)\n",
    "        num_special_tokens=0\n",
    "    )\n",
    "\n",
    "    model = skorch.NeuralNetClassifier(\n",
    "            module=module,\n",
    "            criterion=criterion,\n",
    "            optimizer=torch.optim.AdamW,\n",
    "            device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "            batch_size=128,\n",
    "            max_epochs=12,\n",
    "            train_split=dataset.CVSplit(cv=0.15),\n",
    "            callbacks=[\n",
    "                (\"balanced_accuracy\", skorch.callbacks.EpochScoring(\"balanced_accuracy\", lower_is_better=False)),\n",
    "                (\"accuracy\", skorch.callbacks.EpochScoring(\"accuracy\", lower_is_better=False)),\n",
    "                (\"roc_auc\", skorch.callbacks.EpochScoring(\"roc_auc\", lower_is_better=False)),\n",
    "                (\"f1\", skorch.callbacks.EpochScoring(\"f1\", lower_is_better=False)),\n",
    "                (\"precision\", skorch.callbacks.EpochScoring(\"precision\", lower_is_better=False)),\n",
    "                (\"recall\", skorch.callbacks.EpochScoring(\"recall\", lower_is_better=False))\n",
    "            ],\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.00000000e+00,  1.60000000e+01,  4.00000000e+00,\n",
       "         2.00000000e+00,  4.00000000e+00,  5.00000000e+00,\n",
       "         1.00000000e+00,  1.40000000e+01, -1.15046758e+00,\n",
       "         2.89216869e+00, -3.80074141e-02, -1.46859301e-01,\n",
       "        -2.15354774e-01, -3.60679944e-02],\n",
       "       [ 5.00000000e+00,  1.60000000e+01,  1.00000000e+00,\n",
       "         2.00000000e+00,  5.00000000e+00,  5.00000000e+00,\n",
       "         1.00000000e+00,  4.00000000e+01,  4.67736094e-01,\n",
       "         1.41924226e+00, -3.80074141e-02, -1.46859301e-01,\n",
       "        -2.15354774e-01, -3.60679944e-02],\n",
       "       [ 6.00000000e+00,  1.20000000e+01,  7.00000000e+00,\n",
       "         9.00000000e+00,  5.00000000e+00,  5.00000000e+00,\n",
       "         1.00000000e+00,  4.00000000e+01,  2.15949448e+00,\n",
       "        -5.07547252e-01, -4.26395104e-01, -1.46859301e-01,\n",
       "        -2.15354774e-01, -2.07068513e+00]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_features[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((26048, 14), (26048,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_features.shape, all_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying:  {'optimizer__weight_decay': 0.0001, 'optimizer__lr': 0.0001, 'module__ff_dropout': 0.2, 'module__attn_dropout': 0.5}\n",
      "  epoch    accuracy    balanced_accuracy      f1    precision    recall    roc_auc    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ----------  -------------------  ------  -----------  --------  ---------  ------------  -----------  ------------  ------\n",
      "      1      \u001b[36m0.8227\u001b[0m               \u001b[32m0.7650\u001b[0m  \u001b[35m0.6488\u001b[0m       \u001b[31m0.6491\u001b[0m    \u001b[94m0.6484\u001b[0m     \u001b[36m0.8695\u001b[0m        \u001b[32m0.4334\u001b[0m       \u001b[35m0.8227\u001b[0m        \u001b[31m0.3967\u001b[0m  5.0488\n",
      "      2      \u001b[36m0.8303\u001b[0m               \u001b[32m0.7715\u001b[0m  \u001b[35m0.6602\u001b[0m       \u001b[31m0.6680\u001b[0m    \u001b[94m0.6525\u001b[0m     \u001b[36m0.8807\u001b[0m        \u001b[32m0.3806\u001b[0m       \u001b[35m0.8303\u001b[0m        \u001b[31m0.3744\u001b[0m  4.6379\n",
      "      3      \u001b[36m0.8321\u001b[0m               \u001b[32m0.7780\u001b[0m  \u001b[35m0.6680\u001b[0m       0.6673    \u001b[94m0.6687\u001b[0m     \u001b[36m0.8844\u001b[0m        \u001b[32m0.3715\u001b[0m       \u001b[35m0.8321\u001b[0m        \u001b[31m0.3693\u001b[0m  4.9332\n",
      "      4      0.8257               0.7634  0.6488       0.6607    0.6373     0.8805        \u001b[32m0.3648\u001b[0m       0.8257        0.3773  4.8270\n",
      "      5      0.8250               0.7645  0.6496       0.6570    0.6424     0.8805        0.3652       0.8250        0.3704  4.4648\n",
      "      6      0.8286               \u001b[32m0.7948\u001b[0m  \u001b[35m0.6816\u001b[0m       0.6419    \u001b[94m0.7264\u001b[0m     \u001b[36m0.8924\u001b[0m        \u001b[32m0.3540\u001b[0m       0.8286        \u001b[31m0.3692\u001b[0m  4.6686\n",
      "      7      \u001b[36m0.8350\u001b[0m               \u001b[32m0.8007\u001b[0m  \u001b[35m0.6912\u001b[0m       0.6552    \u001b[94m0.7315\u001b[0m     \u001b[36m0.8977\u001b[0m        \u001b[32m0.3448\u001b[0m       \u001b[35m0.8350\u001b[0m        0.3703  4.7218\n",
      "      8      \u001b[36m0.8406\u001b[0m               \u001b[32m0.8236\u001b[0m  \u001b[35m0.7144\u001b[0m       0.6524    \u001b[94m0.7893\u001b[0m     \u001b[36m0.9066\u001b[0m        \u001b[32m0.3326\u001b[0m       \u001b[35m0.8406\u001b[0m        \u001b[31m0.3502\u001b[0m  5.0498\n",
      "      9      \u001b[36m0.8480\u001b[0m               0.8057  0.7054       \u001b[31m0.6910\u001b[0m    0.7204     \u001b[36m0.9090\u001b[0m        \u001b[32m0.3223\u001b[0m       \u001b[35m0.8480\u001b[0m        \u001b[31m0.3332\u001b[0m  4.7613\n",
      "     10      \u001b[36m0.8521\u001b[0m               0.8075  0.7101       \u001b[31m0.7031\u001b[0m    0.7173     \u001b[36m0.9091\u001b[0m        \u001b[32m0.3185\u001b[0m       \u001b[35m0.8521\u001b[0m        \u001b[31m0.3264\u001b[0m  4.8916\n",
      "Trying:  {'optimizer__weight_decay': 1e-05, 'optimizer__lr': 0.01, 'module__ff_dropout': 0.5, 'module__attn_dropout': 0}\n",
      "  epoch    accuracy    balanced_accuracy      f1    precision    recall    roc_auc    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ----------  -------------------  ------  -----------  --------  ---------  ------------  -----------  ------------  ------\n",
      "      1      \u001b[36m0.8176\u001b[0m               \u001b[32m0.6719\u001b[0m  \u001b[35m0.5086\u001b[0m       \u001b[31m0.7351\u001b[0m    \u001b[94m0.3888\u001b[0m     \u001b[36m0.8758\u001b[0m        \u001b[32m0.4254\u001b[0m       \u001b[35m0.8176\u001b[0m        \u001b[31m0.3803\u001b[0m  4.9244\n",
      "      2      \u001b[36m0.8321\u001b[0m               \u001b[32m0.7030\u001b[0m  \u001b[35m0.5667\u001b[0m       \u001b[31m0.7593\u001b[0m    \u001b[94m0.4521\u001b[0m     \u001b[36m0.8818\u001b[0m        \u001b[32m0.3827\u001b[0m       \u001b[35m0.8321\u001b[0m        \u001b[31m0.3779\u001b[0m  4.6625\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"optimizer__lr\": [10e-6, 10e-5, 10e-4, 10e-3],    \n",
    "    \"optimizer__weight_decay\": [10e-6, 10e-5, 10e-4, 10e-3, 10e-2, 10e-1],\n",
    "    \"module__attn_dropout\": [0, 0.1, 0.2, 0.3, 0.4, 0.5], # Used dropout\n",
    "    \"module__ff_dropout\": [0, 0.1, 0.2, 0.3, 0.4, 0.5], # Used dropout            \n",
    "}\n",
    "\n",
    "for sel_params in model_selection.ParameterSampler(params, n_iter=10):\n",
    "    print(\"Trying: \", sel_params)\n",
    "    build_model(sel_params).fit(X={\n",
    "        \"x_categ\": all_features[:, :8].astype(np.int32), \n",
    "        \"x_cont\": all_features[:, 8:].astype(np.float32)\n",
    "        }, \n",
    "        y=all_labels[:, np.newaxis].astype(np.double)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict_proba({\n",
    "        \"x_categ\": test_features[:, :8].astype(np.int32), \n",
    "        \"x_cont\": test_features[:, 8:].astype(np.float32)\n",
    "        })\n",
    "\n",
    "metrics.roc_auc_score(test_labels, preds[:, 1])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.11 ('DCC-attn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "741e1ea5cc84540885a0ba493c428a89b760d4b9c08bcc57bb2b1068c5ec8401"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
