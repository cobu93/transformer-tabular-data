{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "\n",
    "import skorch\n",
    "from skorch import dataset\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from ndsl.architecture.attention import TabularTransformer\n",
    "\n",
    "from sklearn import base, pipeline, preprocessing, compose, metrics, model_selection\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n",
    "numerical_cols = ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "label_col = \"class\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"adult/data/dataset.csv\")\n",
    "data[label_col] = data[label_col].replace({\"<=50K\": 0, \">50K\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age               0\n",
       "workclass         0\n",
       "fnlwgt            0\n",
       "education         0\n",
       "education-num     0\n",
       "marital-status    0\n",
       "occupation        0\n",
       "relationship      0\n",
       "race              0\n",
       "sex               0\n",
       "capital-gain      0\n",
       "capital-loss      0\n",
       "hours-per-week    0\n",
       "native-country    0\n",
       "class             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size=0.65\n",
    "val_size=0.15\n",
    "test_size=0.20\n",
    "seed=11\n",
    "\n",
    "\n",
    "train_features, test_features, train_labels, test_labels = model_selection.train_test_split(\n",
    "    data[categorical_cols + numerical_cols], \n",
    "    data[label_col], \n",
    "    test_size=test_size,\n",
    "    random_state=seed\n",
    ")\n",
    "\n",
    "val_size = data.shape[0] * val_size / train_features.shape[0]\n",
    "\n",
    "train_features, val_features, train_labels, val_labels = model_selection.train_test_split(\n",
    "    train_features, \n",
    "    train_labels, \n",
    "    test_size=val_size, \n",
    "    random_state=seed\n",
    ")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bins = 10\n",
    "n_quantiles = 10\n",
    "\n",
    "categorical_transformer = pipeline.Pipeline(steps=[\n",
    "    ('label', preprocessing.OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)),\n",
    "    ('shift', preprocessing.FunctionTransformer(lambda x: x + 1))\n",
    "])\n",
    "\n",
    "numerical_transformer = pipeline.FeatureUnion([\n",
    "#    ('qtscaler', preprocessing.QuantileTransformer(n_quantiles=n_quantiles)),\n",
    "    ('sscaler', preprocessing.StandardScaler()),\n",
    "#    ('logscaler', preprocessing.FunctionTransformer(np.log1p)),\n",
    "])\n",
    "\n",
    "numerical_categorical_transformer = pipeline.Pipeline(steps=[\n",
    "    ('dscaler', preprocessing.KBinsDiscretizer(n_bins=n_bins, encode=\"ordinal\", strategy=\"uniform\")), \n",
    "])\n",
    "\n",
    "\n",
    "preprocessor = pipeline.Pipeline([\n",
    "    ('columns_transformer', compose.ColumnTransformer(\n",
    "        remainder='passthrough', #passthough features not listed\n",
    "        transformers=[\n",
    "            ('categorical_transformer', categorical_transformer , categorical_cols),\n",
    "            #('numerical_categorical_transformer', numerical_categorical_transformer , numerical_cols),\n",
    "            ('numerical_transformer', numerical_transformer , numerical_cols)\n",
    "        ]),\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training examples 21163 (0.6499493258806548)\n",
      "Validation examples 4885 (0.15002610484935966)\n",
      "Test examples 6513 (0.20002456926998557)\n"
     ]
    }
   ],
   "source": [
    "total_examples = train_features.shape[0] + val_features.shape[0] + test_features.shape[0]\n",
    "\n",
    "print(\"Training examples {} ({})\".format(train_features.shape[0], train_features.shape[0] / total_examples))\n",
    "print(\"Validation examples {} ({})\".format(val_features.shape[0], val_features.shape[0] / total_examples))\n",
    "print(\"Test examples {} ({})\".format(test_features.shape[0], test_features.shape[0] / total_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = preprocessor.fit(train_features, train_labels)\n",
    "\n",
    "train_features = preprocessor.transform(train_features)\n",
    "val_features = preprocessor.transform(val_features)\n",
    "test_features = preprocessor.transform(test_features)\n",
    "\n",
    "all_features = np.concatenate([train_features, val_features])\n",
    "all_labels = np.concatenate([train_labels, val_labels])\n",
    "\n",
    "n_labels = 1\n",
    "criterion = torch.nn.BCEWithLogitsLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(*args, **kwargs):\n",
    "    \n",
    "    module = TabularTransformer(\n",
    "        n_categories=(9, 17, 8, 15, 7, 6, 3, 42), # List of number of categories\n",
    "        n_numerical=6, # Number of numerical features\n",
    "        n_head=8, # Number of heads per layer\n",
    "        n_hid=128, # Size of the MLP inside each transformer encoder layer\n",
    "        n_layers=6, # Number of transformer encoder layers    \n",
    "        n_output=1, # The number of output neurons\n",
    "        embed_dim=32,\n",
    "        aggregator=\"rnn\", # The aggregator for output vectors before decoder\n",
    "        rnn_aggregator_parameters={\n",
    "            \"output_size\": 128,\n",
    "            \"cell\": \"GRU\",\n",
    "            \"num_layers\": 1,\n",
    "            \"dropout\": 0\n",
    "        },\n",
    "        decoder_hidden_units=[128, 64],\n",
    "        decoder_activation_fn=nn.ReLU(),\n",
    "        need_weights=False,\n",
    "        numerical_passthrough=True\n",
    "    )\n",
    "\n",
    "    model = skorch.NeuralNetClassifier(\n",
    "            module=module,\n",
    "            criterion=criterion,\n",
    "            optimizer=torch.optim.AdamW,\n",
    "            device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "            batch_size=128,\n",
    "            max_epochs=12,\n",
    "            train_split=dataset.CVSplit(cv=0.15),\n",
    "            callbacks=[\n",
    "                (\"balanced_accuracy\", skorch.callbacks.EpochScoring(\"balanced_accuracy\", lower_is_better=False)),\n",
    "                (\"accuracy\", skorch.callbacks.EpochScoring(\"accuracy\", lower_is_better=False)),\n",
    "                (\"roc_auc\", skorch.callbacks.EpochScoring(\"roc_auc\", lower_is_better=False)),\n",
    "                (\"f1\", skorch.callbacks.EpochScoring(\"f1\", lower_is_better=False)),\n",
    "                (\"precision\", skorch.callbacks.EpochScoring(\"precision\", lower_is_better=False)),\n",
    "                (\"recall\", skorch.callbacks.EpochScoring(\"recall\", lower_is_better=False))\n",
    "            ],\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.00000000e+00,  1.60000000e+01,  4.00000000e+00,\n",
       "         2.00000000e+00,  4.00000000e+00,  5.00000000e+00,\n",
       "         1.00000000e+00,  1.40000000e+01, -1.15046758e+00,\n",
       "         2.89216869e+00, -3.80074141e-02, -1.46859301e-01,\n",
       "        -2.15354774e-01, -3.60679944e-02],\n",
       "       [ 5.00000000e+00,  1.60000000e+01,  1.00000000e+00,\n",
       "         2.00000000e+00,  5.00000000e+00,  5.00000000e+00,\n",
       "         1.00000000e+00,  4.00000000e+01,  4.67736094e-01,\n",
       "         1.41924226e+00, -3.80074141e-02, -1.46859301e-01,\n",
       "        -2.15354774e-01, -3.60679944e-02],\n",
       "       [ 6.00000000e+00,  1.20000000e+01,  7.00000000e+00,\n",
       "         9.00000000e+00,  5.00000000e+00,  5.00000000e+00,\n",
       "         1.00000000e+00,  4.00000000e+01,  2.15949448e+00,\n",
       "        -5.07547252e-01, -4.26395104e-01, -1.46859301e-01,\n",
       "        -2.15354774e-01, -2.07068513e+00]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_features[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((26048, 14), (26048,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_features.shape, all_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying:  {'optimizer__weight_decay': 0.001, 'optimizer__lr': 0.001, 'module__ff_dropout': 0.5, 'module__attn_dropout': 0.3}\n",
      "  epoch    accuracy    balanced_accuracy      f1    precision    recall    roc_auc    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ----------  -------------------  ------  -----------  --------  ---------  ------------  -----------  ------------  ------\n",
      "      1      \u001b[36m0.8025\u001b[0m               \u001b[32m0.6366\u001b[0m  \u001b[35m0.4357\u001b[0m       \u001b[31m0.7286\u001b[0m    \u001b[94m0.3107\u001b[0m     \u001b[36m0.8422\u001b[0m        \u001b[32m0.4737\u001b[0m       \u001b[35m0.8025\u001b[0m        \u001b[31m0.4131\u001b[0m  5.1892\n",
      "      2      \u001b[36m0.8211\u001b[0m               \u001b[32m0.7274\u001b[0m  \u001b[35m0.5985\u001b[0m       0.6662    \u001b[94m0.5433\u001b[0m     \u001b[36m0.8503\u001b[0m        \u001b[32m0.4131\u001b[0m       \u001b[35m0.8211\u001b[0m        \u001b[31m0.3965\u001b[0m  5.3143\n",
      "      3      \u001b[36m0.8255\u001b[0m               \u001b[32m0.7355\u001b[0m  \u001b[35m0.6112\u001b[0m       0.6742    \u001b[94m0.5589\u001b[0m     \u001b[36m0.8520\u001b[0m        \u001b[32m0.4107\u001b[0m       \u001b[35m0.8255\u001b[0m        \u001b[31m0.3939\u001b[0m  5.5913\n",
      "      4      0.8240               0.7264  0.5986       0.6795    0.5349     0.8515        \u001b[32m0.4086\u001b[0m       0.8240        0.3946  5.6484\n",
      "      5      \u001b[36m0.8265\u001b[0m               0.7098  0.5763       0.7192    0.4807     \u001b[36m0.8521\u001b[0m        \u001b[32m0.4084\u001b[0m       \u001b[35m0.8265\u001b[0m        \u001b[31m0.3937\u001b[0m  5.7665\n",
      "      6      0.8232               0.7217  0.5918       0.6826    0.5224     0.8518        \u001b[32m0.4067\u001b[0m       0.8232        \u001b[31m0.3934\u001b[0m  5.6698\n",
      "      7      \u001b[36m0.8268\u001b[0m               0.7023  0.5646       \u001b[31m0.7366\u001b[0m    0.4578     \u001b[36m0.8531\u001b[0m        0.4071       \u001b[35m0.8268\u001b[0m        0.3934  5.3647\n",
      "      8      0.8260               0.7236  0.5957       0.6929    0.5224     0.8527        \u001b[32m0.4064\u001b[0m       0.8260        0.3937  5.6439\n",
      "Trying:  {'optimizer__weight_decay': 1e-05, 'optimizer__lr': 0.0001, 'module__ff_dropout': 0.1, 'module__attn_dropout': 0.5}\n",
      "  epoch    accuracy    balanced_accuracy      f1    precision    recall    roc_auc    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ----------  -------------------  ------  -----------  --------  ---------  ------------  -----------  ------------  ------\n",
      "      1      \u001b[36m0.7602\u001b[0m               \u001b[32m0.5569\u001b[0m  \u001b[35m0.2401\u001b[0m       \u001b[31m0.5670\u001b[0m    \u001b[94m0.1523\u001b[0m     \u001b[36m0.7666\u001b[0m        \u001b[32m0.5137\u001b[0m       \u001b[35m0.7602\u001b[0m        \u001b[31m0.4839\u001b[0m  5.3705\n",
      "      2      \u001b[36m0.8007\u001b[0m               \u001b[32m0.7201\u001b[0m  \u001b[35m0.5828\u001b[0m       \u001b[31m0.6078\u001b[0m    \u001b[94m0.5597\u001b[0m     \u001b[36m0.8415\u001b[0m        \u001b[32m0.4313\u001b[0m       \u001b[35m0.8007\u001b[0m        \u001b[31m0.4117\u001b[0m  5.3195\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"optimizer__lr\": [10e-6, 10e-5, 10e-4, 10e-3],    \n",
    "    \"optimizer__weight_decay\": [10e-6, 10e-5, 10e-4, 10e-3, 10e-2, 10e-1],     \n",
    "    \"module__attn_dropout\": [0, 0.1, 0.2, 0.3, 0.4, 0.5], # Used dropout\n",
    "    \"module__ff_dropout\": [0, 0.1, 0.2, 0.3, 0.4, 0.5], # Used dropout  \n",
    "}\n",
    "\n",
    "for sel_params in model_selection.ParameterSampler(params, n_iter=10):\n",
    "    print(\"Trying: \", sel_params)\n",
    "    build_model(sel_params).fit(X={\n",
    "        \"x_categorical\": all_features[:, :8].astype(np.int32), \n",
    "        \"x_numerical\": all_features[:, 8:].astype(np.float32)\n",
    "        }, \n",
    "        y=all_labels.astype(np.double)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict_proba({\n",
    "        \"x_categ\": test_features[:, :8].astype(np.int32), \n",
    "        \"x_cont\": test_features[:, 8:].astype(np.float32)\n",
    "        })\n",
    "\n",
    "metrics.roc_auc_score(test_labels, preds[:, 1])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.11 ('DCC-attn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "741e1ea5cc84540885a0ba493c428a89b760d4b9c08bcc57bb2b1068c5ec8401"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
