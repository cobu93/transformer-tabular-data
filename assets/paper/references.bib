@article{ref:openml,
    title = {{OpenML}: An {R} Package to Connect to the Machine
      Learning Platform {OpenML}},
    author = {Giuseppe Casalicchio and Jakob Bossek and Michel Lang and
      Dominik Kirchhoff and Pascal Kerschke and Benjamin Hofner and
      Heidi Seibold and Joaquin Vanschoren and Bernd Bischl},
    journal = {Computational Statistics},
    year = {2017},
    pages = {1--15},
    doi = {10.1007/s00180-017-0742-2},
    url = {http://dx.doi.org/10.1007/s00180-017-0742-2},
  }

@article{ref:kmeans,  
    author={Lloyd, S.},  
    journal={IEEE Transactions on Information Theory},   
    title={Least squares quantization in PCM},   
    year={1982},  
    volume={28},  
    number={2},  
    pages={129-137},  
    doi={10.1109/TIT.1982.1056489}
}

@article{ref:tsne,
  title={Visualizing Data using t-SNE},
  author={Laurens van der Maaten and Geoffrey E. Hinton},
  journal={Journal of Machine Learning Research},
  year={2008},
  volume={9},
  pages={2579-2605}
}

@article{ref:tune,
    title={Tune: A Research Platform for Distributed Model Selection and Training},
    author={Liaw, Richard and Liang, Eric and Nishihara, Robert
            and Moritz, Philipp and Gonzalez, Joseph E and Stoica, Ion},
    journal={arXiv preprint arXiv:1807.05118},
    year={2018}
}

@inproceedings{ref:optuna,
    title={Optuna: A Next-generation Hyperparameter Optimization Framework},
    author={Akiba, Takuya and Sano, Shotaro and Yanase, Toshihiko and Ohta, Takeru and Koyama, Masanori},
    booktitle={Proceedings of the 25rd {ACM} {SIGKDD} International Conference on Knowledge Discovery and Data Mining},
    year={2019}
}

@inproceedings{ref:tpe,
 author = {Bergstra, James and Bardenet, R\'{e}mi and Bengio, Yoshua and K\'{e}gl, Bal\'{a}zs},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {J. Shawe-Taylor and R. Zemel and P. Bartlett and F. Pereira and K.Q. Weinberger},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Algorithms for Hyper-Parameter Optimization},
 url = {https://proceedings.neurips.cc/paper/2011/file/86e8f7ab32cfd12577bc2619bc635690-Paper.pdf},
 volume = {24},
 year = {2011}
}

@misc{ref:asha,
    title={Massively Parallel Hyperparameter Tuning},
    author={Lisha Li and Kevin Jamieson and Afshin Rostamizadeh and Katya Gonina and Moritz Hardt and Benjamin Recht and Ameet Talwalkar},
    year={2018},
    url={https://openreview.net/forum?id=S1Y7OOlRZ}
}

@inproceedings{ref:balanced_acc,  
    author={Brodersen, Kay Henning and Ong, Cheng Soon and Stephan, Klaas Enno and Buhmann, Joachim M.},  
    booktitle={2010 20th International Conference on Pattern Recognition},   
    title={The Balanced Accuracy and Its Posterior Distribution},   
    year={2010},  
    volume={},  
    number={},  
    pages={3121-3124},  
    doi={10.1109/ICPR.2010.764}
}

@misc{ref:tabular_transformer,
  doi = {10.48550/ARXIV.2012.06678},
  url = {https://arxiv.org/abs/2012.06678},
  author = {Huang, Xin and Khetan, Ashish and Cvitkovic, Milan and Karnin, Zohar},
  keywords = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {TabTransformer: Tabular Data Modeling Using Contextual Embeddings},
  publisher = {arXiv},
  year = {2020},
  copyright = {Creative Commons Zero v1.0 Universal}
}

@misc{ref:transformer,
  doi = {10.48550/ARXIV.1706.03762},
  url = {https://arxiv.org/abs/1706.03762},
  author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
  keywords = {Computation and Language (cs.CL), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Attention Is All You Need},
  publisher = {arXiv},
  year = {2017},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{ref:revisiting_dl_tab,
  doi = {10.48550/ARXIV.2106.11959},
  url = {https://arxiv.org/abs/2106.11959},
  author = {Gorishniy, Yury and Rubachev, Ivan and Khrulkov, Valentin and Babenko, Artem},
  keywords = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Revisiting Deep Learning Models for Tabular Data},
  publisher = {arXiv},
  year = {2021},
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@misc{ref:weight_normalization,
  doi = {10.48550/ARXIV.1602.07868},
  url = {https://arxiv.org/abs/1602.07868},
  author = {Salimans, Tim and Kingma, Diederik P.},
  keywords = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), Neural and Evolutionary Computing (cs.NE), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Weight Normalization: A Simple Reparameterization to Accelerate Training of Deep Neural Networks},
  publisher = {arXiv},
  year = {2016},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{ref:layer_normalization,
  doi = {10.48550/ARXIV.1607.06450},
  url = {https://arxiv.org/abs/1607.06450},
  author = {Ba, Jimmy Lei and Kiros, Jamie Ryan and Hinton, Geoffrey E.},
  keywords = {Machine Learning (stat.ML), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Layer Normalization},
  publisher = {arXiv},
  year = {2016},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{ref:emb_pooling,
  doi = {10.48550/ARXIV.1801.06146},
  url = {https://arxiv.org/abs/1801.06146},
  author = {Howard, Jeremy and Ruder, Sebastian},
  keywords = {Computation and Language (cs.CL), Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Universal Language Model Fine-tuning for Text Classification},
  publisher = {arXiv},
  year = {2018},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{ref:xgboost,
  author = {Chen, Tianqi and Guestrin, Carlos},
  title = {XGBoost: A Scalable Tree Boosting System},
  year = {2016},
  isbn = {9781450342322},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/2939672.2939785},
  doi = {10.1145/2939672.2939785},
  abstract = {Tree boosting is a highly effective and widely used machine learning method. In this paper, we describe a scalable end-to-end tree boosting system called XGBoost, which is used widely by data scientists to achieve state-of-the-art results on many machine learning challenges. We propose a novel sparsity-aware algorithm for sparse data and weighted quantile sketch for approximate tree learning. More importantly, we provide insights on cache access patterns, data compression and sharding to build a scalable tree boosting system. By combining these insights, XGBoost scales beyond billions of examples using far fewer resources than existing systems.},
  booktitle = {Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  pages = {785-794},
  numpages = {10},
  keywords = {large-scale machine learning},
  location = {San Francisco, California, USA},
  series = {KDD '16}
}

@misc{ref:well_tuned_nets,
  doi = {10.48550/ARXIV.2106.11189},
  url = {https://arxiv.org/abs/2106.11189},
  author = {Kadra, Arlind and Lindauer, Marius and Hutter, Frank and Grabocka, Josif},
  keywords = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Well-tuned Simple Nets Excel on Tabular Datasets},
  publisher = {arXiv},
  year = {2021},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{ref:tabnet,
  doi = {10.48550/ARXIV.1908.07442},
  url = {https://arxiv.org/abs/1908.07442},
  author = {Arik, Sercan O. and Pfister, Tomas},
  keywords = {Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {TabNet: Attentive Interpretable Tabular Learning},
  publisher = {arXiv},
  year = {2019},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{ref:node,
  doi = {10.48550/ARXIV.1909.06312},
  url = {https://arxiv.org/abs/1909.06312},
  author = {Popov, Sergei and Morozov, Stanislav and Babenko, Artem},
  keywords = {Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Neural Oblivious Decision Ensembles for Deep Learning on Tabular Data},
  publisher = {arXiv},
  year = {2019},
  copyright = {Creative Commons Attribution 4.0 International}
}

@inproceedings{ref:random_forest,
  title={Random decision forests},
  author={Ho, Tin Kam},
  booktitle={Proceedings of 3rd international conference on document analysis and recognition},
  volume={1},
  pages={278--282},
  year={1995},
  organization={IEEE}
}

@misc{ref:bert,
  doi = {10.48550/ARXIV.1810.04805},
  url = {https://arxiv.org/abs/1810.04805},
  author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  publisher = {arXiv},
  year = {2018},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
